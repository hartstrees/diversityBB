---
title: "Host richness increases the occurrence but not the severity of bark beetle-induced tree mortality"
author: "Sarah J. Hart et al."
email: "sarah.hart@colostate.edu"
date: '`r format(Sys.time(), "%B %d, %Y")`'
output: 
  bookdown::word_document2:
    reference_docx: WordTemplate.docx
    fig_caption: yes
    toc: no
    number_sections: no
    df_print: kable
csl: "`r here:::here('ecology.csl')`"
bibliography: "`r here:::here('MyLib.bib')`"
urlcolor: blue
linkcolor: blue
citationcolor: blue
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = F,
	message = FALSE,
	warning = FALSE,
	dpi = 300,
	progress = FALSE,
	cache = FALSE
)

ipak <- function(pkg){
    new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
    if (length(new.pkg)>0) {
             install.packages(new.pkg, dependencies = TRUE)
    }
    easypackages::libraries(pkg)
}

options(repos = c(CRAN = "http://cran.rstudio.com"))

### Import libraries
ipak(c('tidyverse', 'tidymodels', 'reshape2', 'here', 'rgdal', 'sp', 'raster', 'stars', 'sf', 'prism', 'tigris', "tmap", 'fasterize', 'ggplot2','RColorBrewer','ggsci', 'patchwork', 'colorspace', 'grid', 'knitr',  'kableExtra', 'bookdown',  'pdp', 'ranger', 'VSURF', 'themis', 'foreach',  'FSA', 'parallel'))

# Set seed
set.seed(2020)

# Set number of cores for parralell processing
cores <- parallel::detectCores()

# Set custom plotting theme
theme_new <- function(base_size = 9,base_family = "Helvetica"){
  theme_classic(base_size = base_size, base_family = base_family) %+replace%
    theme(
      axis.line.x = element_line(color="black", size = 0.25),
      axis.line.y = element_line(color="black", size = 0.25),
      axis.title = element_text(size = 9),
      axis.text = element_text(colour="black", size=8),
      legend.key=element_rect(colour=NA, fill =NA),
      panel.grid = element_blank(),   
      plot.background = element_rect(fill = NA, colour = NA),
      panel.border = element_rect(fill = NA, colour = NA),
      panel.background = element_rect(fill = "white", colour = "black"), 
      strip.background = element_rect(fill = "white"),
      strip.text = element_text(size = 9)
      
    )
}
theme_black = function(base_size = 12, base_family = "Helvetica") {
  
  theme_grey(base_size = base_size, base_family = base_family) %+replace%
    
    theme(
      # Specify axis options
      axis.line = element_blank(),  
      axis.text.x = element_text(size = base_size*0.8, color = "white", lineheight = 0.9),  
      axis.text.y = element_text(size = base_size*0.8, color = "white", lineheight = 0.9),  
      axis.ticks = element_line(color = "white", size  =  0.2),  
      axis.title.x = element_text(size = base_size, color = "white", margin = margin(10, 0, 0, 0)),  
      axis.title.y = element_text(size = base_size, color = "white", angle = 90, margin = margin(0, 10, 0, 0)),  
      axis.ticks.length = unit(0.3, "lines"),   
      # Specify legend options
      legend.background = element_rect(color = NA, fill = rgb(50, 50, 50, maxColorValue = 255)),  
      legend.key = element_rect(color = "white",  fill = rgb(50, 50, 50, maxColorValue = 255)),  
      legend.key.size = unit(1.2, "lines"),  
      legend.key.height = NULL,  
      legend.key.width = NULL,      
      legend.text = element_text(size = base_size*0.8, color = "white"),  
      legend.title = element_text(size = base_size*0.8, face = "bold", hjust = 0, color = "white"),  
      legend.position = "right",  
      legend.text.align = NULL,  
      legend.title.align = NULL,  
      legend.box = NULL, 
      # Specify panel options
      panel.background = element_rect(fill = rgb(50, 50, 50, maxColorValue = 255), color  =  NA),  
      panel.border = element_rect(fill = NA, color = "white"),  
      panel.grid.major = element_line(color = NA),  
      panel.grid.minor = element_line(color = NA),  
      panel.margin = unit(0.5, "lines"),   
      # Specify facetting options
      strip.background = element_rect(fill = "grey30", color = "grey10"),  
      strip.text.x = element_text(size = base_size*0.8, color = "white"),  
      strip.text.y = element_text(size = base_size*0.8, color = "white",angle = -90),  
      # Specify plot options
      plot.background = element_rect(color =rgb(50, 50, 50, maxColorValue = 255), fill = rgb(50, 50, 50, maxColorValue = 255)),  
      plot.title = element_text(size = base_size*1.2, color = "white"),  
      plot.margin = unit(rep(1, 4), "lines")
      
    )
  
}
theme_set(theme_new())


options(ggplot2.continuous.colour="viridis")
scale_colour_discrete <- scale_fill_npg
scale_fill_discrete <- scale_fill_npg
options(scipen=999)


p1col=c(rgb(104, 17, 10,  maxColorValue = 255), rgb(79, 130, 156, maxColorValue = 255), rgb(243, 173, 1, maxColorValue = 255), rgb(112, 146, 115,  maxColorValue = 255), rgb(112, 146, 115, maxColorValue = 255))

p1fill=c(rgb(104, 17, 10, alpha=230, maxColorValue = 255), rgb(79, 130, 156, alpha=230, maxColorValue = 255), rgb(243, 173, 1, alpha=50, maxColorValue = 255), rgb(112, 146, 115, alpha=230,  maxColorValue = 255), rgb(112, 146, 115, alpha=230, maxColorValue = 255))

p2col =c(rgb(20,20,20, maxColorValue = 255), rgb(54, 124, 111, maxColorValue = 255), rgb(235, 137, 52, maxColorValue = 255), rgb(83, 74, 90, maxColorValue = 255), rgb(232, 177, 60, maxColorValue = 255),rgb(90, 129, 154, maxColorValue = 255),rgb(113, 0, 2, maxColorValue = 255), rgb(166, 166, 166,  maxColorValue = 255))

fig.width1 <- 3.4
fig.width2 <- 7
fig.width1.5 <- 4.48

pt.width1 <-fig.width1 * 72
pt.width2 <-fig.width2 * 72
pt.width1.5 <- fig.width1.5 * 72

# Set projection - NAD83 / Conus Albers
aea.proj <- "EPSG:5070"

options(timeout=60*30) #timeout downloads that last longer than 30 minutes


# Set directory structure for project
dir.create(here("Data/"), showWarnings = FALSE)
dir.create(here("Results/"), showWarnings = FALSE)
dir.create(here("Results/Figures/"), showWarnings = FALSE)
```

# Abstract

# Keywords


# Introduction

Paragraph 1: Broad applied context

In this context there is a particular need to understand interactions between outbreaks of irruptive insects, which in recent years (2003-2012) have affected 85 million hectares of forest globally, or ca. 18 million hectares more than wildfire (van Lierop et al. 2015). 

- insect outbreaks are causing widespread tree mortality in temperate forest worldwide
- future changes in climate are expected to increase tree mortality
- forests provide key ecosystem services
- management

Paragraph 2: Theoretical context - diversity & natural enemies

Many studies have sought to understand how community diversity influences interactions between natural enemies and their resources. In the case of plant-herbivore interactions, the greater plant diversity often reduces herbivory effects on plants at both the individual and population level [i.e. 'associational resistance, @barbosa_associational_2009, @jactel_tree_2021]. The resource concentration hypothesis suggests that specialists insect herbivores are less likely to find and stay in stands where their hosts are less abundant [@root_organization_1973]. This may occur if insects are less likely to find a host tree due [i.e. 'host dilution effect', @] or chemical masking of the focal tree by heterospecific neighbors [i.e. 'host apparency hypothesis', @Castagneryrol_effects_2014]

[i.e., 'resource concentration hypothesis', @root_organization_1973].

However, benefits provided by mixtures are less evident for larger-scale disturbances [@jactel_tree_2021]
suggesting that changes in the structure of host communities, rather than biodiversity per se, can explain when a dilution effect should be observed. 


1 - associational resistance - the abundance or damage of herbivores is lower when plant diversity is greater [@barbosa_associational_2009, @jactel_tree_2021]
hypotheses:
1 - resource concentration: the presence of heterospecific neighbors around a tree of a focal species grown in mixed stands leads to a lower probability of host tree finding by insect herbivores due to lower host abundance or frequency [@root_organization_1973]
2 - host apparency: 
3 - decoy: preference for non-host trees


H
Most studies have focused on individual- or population-level outcomes. 

For instance, increased host community diversity may either increase or decrease the susceptibility of individuals to their natural enemies. 

At the population-scale these effects may either scale-up or result in counter-intuitive effects. However, little research has examined community-level outcomes, which are often hard to quantify because of the number of potential interactions increases dramatically with increasing community diversity, particularly when natural enemies are generalists. Further, the effects of different natural enemies on their focal host populations often differ greatly, due to differences in susceptibility and mortality rates and the availability and quality (as viewed by their natural enemies) of resource communities. Critically, community-level outcomes may drive ecosystem processes, particularly when community diversity is low and natural enemy-resource relationships are highly dynamic. 

*** paragraph about irruptive species and community host diversity*** 
- stand scale
- landscape scale

To better understand how community diversity influences interactions between natural enemies and their resources, we use a natural system with inherently low resource and natural enemy diversity. Specifically our research focuses on tree mortality due to three bark beetle species, the mountain pine beetle (*Dendroctonus ponderosae*), spruce beetle (*D. rufipennis*), and western balsam bark beetle (*Dryocoetes confusus*), which in subalpine forests of Western North America predominantly attack lodgepole pine (*Pinus contorta*), Engelmann spruce (*Picea engelmannii*), and subalpine fir (*Abies lasiocarpa*), respectively. We use this system to ask whether host tree richness or identity influence the occurrence and severity of tree mortality due to bark beetles at the community-scale? We hypothesize that
greater host richness will increase the probability of outbreak occurrence 

Bark beetles (Curculionidae: Scolytinae) are among the few native insect species that can kill large numbers of trees in a single year. Bark beetles bore through the bark, where they mate and oviposit their eggs. Concurrently, bark beetles introduce pathogenic fungi Larvae feeding upon the phloem and fungal spread stop the translocation of water and nutrients and cause tree death. Conifer defense against bark beetles consists primarily of resin exudation that physically expels the beetle and allelochemicals, which repel or kill beetles. To overcome these defenses and colonize live trees, bark beetles rely on a mass-attack strategy, where pioneering beetles emit aggregation pheromones that call conspecifics to the tree. Typically bark beetles exist at low population levels and attack weakened trees, but as populations increase bark beetles attack increasingly better defended trees.For instance, in the continental western United States bark beetles have killed more than XXXX trees over the past X decades. Such severe mortality occurs only during outbreaks when pheromone-mediated mass-attack allows bark beetles to overcome tree defenses. 

For instance, a primary goal of the Western Bark Beetle is to promote resilience of forests to bark beetle outbreaks by increasing the diversity of age classes and tree species. 


To test these hypotheses, we used a large dataset consisting of XXX,XXX plots established by the United States Forest Service Forest Inventory and Analysis Program (FIA; https://www.fia.fs.fed.us/). 

We expect that co-occurrence of trees of different host species will be common, but co-occurrence of stand conditions suitable for multiple bark beetle species will not. Given stands where conditions are suitable for multiple bark beetle species, occurrence of bark beetle-driven tree mortality will be greater (i.e. diversity begets diversity), but severity will be lower (i.e. resource concentration). 

We also expected the severity of bark beetle infestation to vary with the number of agents present, but with two alternative hypotheses. If the population dynamics of each bark beetle species are independent, then stands with multiple agents will experience higher tree mortality than stands with only one agent (i.e. additive effects). Alternatively, lower tree mortality may occur if concurrent outbreaks of bark beetles of different species cause semiochemical confusion or if competitive release increases tree defensive capacity. 


# Methods

## Study area
```{r set species and agent codes}
# SPECIES CODES

# MPBhosts
PICO <- 108
PIAL <- 101
PIAR <- 102
PIFL <- 113
PIST <- 114
PIMO <- 119
PIPO <- 122

# SBhosts
PIEN <- 93
PIPU <- 96

#SFDhosts
ABLA <-19 
ABCO <- 15
ABGR <- 17

ohostsMPB <- c( PIAL, PIAR, PIFL, PIST, PIMO, PIPO)
ohostsWBBB <- c(ABCO, ABGR)
ohostsSB <- PIPU
otherhosts <- c(ABCO, ABGR, PIPU, PIAL, PIAR, PIFL, PIST, PIMO, PIPO)

# AGENT CODES
# DCA
bb <- 11000 #bark beetle
mpb <- 11006 #mountain pine beetle
sb <- 11009 #spruce beetle
wbbb <- 11015 # western balsam bark beetle
sfm <- 80002 # subalpine fir mortality
```

The study area consists of subalpine lodgepole pine (*Pinus contorta*), subalpine fir (*Abies lasiocarpa*), and Engelmann spruce (*Picea engelmannii*) forest in the Intermountain West (i.e., Arizona, New Mexico, Colorado, Utah, Nevada, Idaho, Montana, Wyoming)


## Data
### FIA data

The FIA program is a single inventory program that includes all public and private forested land (>= 0.4 ha in size and >= 10% canopy cover) in the US. In the Western US, all plots are visited once every ten years [@gray_forest_2012]. The spatially and temporally distributed probabilistic sampling design is useful studies of the distribution of tree species [e.g., @iverson_predicting_1998; @rehfeldt_empirical_2006], forest insects [e.g., @derose_effects_2013], and tree mortality [e.g., @shaw_forest_2005]

At each FIA plot, field crews collect data for trees (>= 12.7 cm DBH) within four 7.32 m radius subplots arranged in a fixed pattern. Data on the proximate cause of death is collected for any tree (>= 12.7 cm DBH) that was alive at the previous visit and at revisit is dead using visible evidence (e.g., fire scars, bark beetle galleries).


```{r download FIA data, eval=F}
dir.create(here("Data/"), showWarnings = FALSE)
dir.create(here("Data/FIA"), showWarnings = FALSE)
# reference data
dir.create(here("Data/FIA/Reference"), showWarnings = FALSE)
temp <- here("/Data/FIA/Reference/FIADB_REFERENCE.zip")
download.file("https://apps.fs.usda.gov/fia/datamart/CSV/FIADB_REFERENCE.zip", temp)
unzip(temp, exdir=here("/Data/FIA/Reference"))

# AZ
dir.create(here("Data/FIA/AZ"), showWarnings = FALSE)
temp <- here("/Data/FIA/AZ/AZ.zip")
download.file("https://apps.fs.usda.gov/fia/datamart/CSV/AZ.zip", temp)
unzip(temp, exdir=here("/Data/FIA/AZ"))

# CO
dir.create(here("Data/FIA/CO"), showWarnings = FALSE)
temp <- here("/Data/FIA/CO/CO.zip")
download.file("https://apps.fs.usda.gov/fia/datamart/CSV/CO.zip", temp)
unzip(temp, exdir=here("/Data/FIA/CO"))

# ID
dir.create(here("Data/FIA/ID"), showWarnings = FALSE)
temp <- here("/Data/FIA/ID/ID.zip")
download.file("https://apps.fs.usda.gov/fia/datamart/CSV/ID.zip", temp)
unzip(temp, exdir=here("/Data/FIA/ID"))

# MT
dir.create(here("Data/FIA/MT"), showWarnings = FALSE)
temp <- here("/Data/FIA/MT/MT.zip")
download.file("https://apps.fs.usda.gov/fia/datamart/CSV/MT.zip", temp)
unzip(temp, exdir=here("/Data/FIA/MT"))

# NM
dir.create(here("Data/FIA/NM"), showWarnings = FALSE)
temp <- here("/Data/FIA/NM/NM.zip")
download.file("https://apps.fs.usda.gov/fia/datamart/CSV/NM.zip", temp)
unzip(temp, exdir=here("/Data/FIA/NM"))

# NV
dir.create(here("Data/FIA/NV"), showWarnings = FALSE)
temp <- here("/Data/FIA/NV/NV.zip")
download.file("https://apps.fs.usda.gov/fia/datamart/CSV/NV.zip", temp)
unzip(temp, exdir=here("/Data/FIA/NV"))

# UT
dir.create(here("Data/FIA/UT"), showWarnings = FALSE)
temp <- here("/Data/FIA/UT/UT.zip")
download.file("https://apps.fs.usda.gov/fia/datamart/CSV/UT.zip", temp)
unzip(temp, exdir=here("/Data/FIA/UT"))

# WY
dir.create(here("Data/FIA/WY"), showWarnings = FALSE)
temp <- here("/Data/FIA/WY/WY.zip")
download.file("https://apps.fs.usda.gov/fia/datamart/CSV/WY.zip", temp)
unzip(temp, exdir=here("/Data/FIA/WY"))
```

```{r download spatial data, eval=F}
# states
dir.create(here("Data/Spatial/"), showWarnings = FALSE)
dir.create(here("Data/Spatial/States"), showWarnings = FALSE)
temp <- here("/Data/Spatial/States/cb_2018_us_state_20m.zip")
download.file("https://www2.census.gov/geo/tiger/GENZ2018/shp/cb_2018_us_state_20m.zip", temp)
unzip(temp, exdir=here("/Data/Spatial/States"))

# usfs western bark beetle strategy
dir.create(here("Data/Spatial/USFS/"), showWarnings = FALSE)
temp <- here("/Data/Spatial/USFS/WBBS_PL.gdb.zip")
download.file("https://data.fs.usda.gov/geodata/edw/edw_resources/fc/S_USA.Activity_WBBS_PL.gdb.zip", temp)
unzip(temp, exdir=here("/Data/Spatial/USFS/"))

# usfs timber harvest
dir.create(here("Data/Spatial/USFS/"), showWarnings = FALSE)
temp <- here("/Data/Spatial/USFS/Activity_TimberHarvest.gdb.zip")
download.file("https://data.fs.usda.gov/geodata/edw/edw_resources/fc/S_USA.Activity_TimberHarvest.gdb.zip", temp)
unzip(temp, exdir=here("/Data/Spatial/USFS/"))
```

```{r import raw data, eval=F}
wd <- here("Data/FIA")

# List directories containing data for each state
dirs <- list.dirs(wd)

dirs <- dirs[c(-1, -8)] 

# Create empty lists to hold dataframe for each state
dats <- list() 
datp <- list()
datc <- list()
datt <- list()
datspc <- list()

for(i in 1:length(dirs)){
  state <- strsplit(dirs[i], split="FIA/")[[1]][2]
  # Survey 
  dats[[state]] <- read.csv(paste0(dirs[i], "/",state, "_SURVEY.csv"), stringsAsFactors = F)
  # Plot
  datp[[state]] <- read.csv(paste0(dirs[i], "/",state, "_PLOT.csv"), stringsAsFactors = F)
  # Condition
  datc[[state]] <- read.csv(paste0(dirs[i], "/",state, "_COND.csv"), stringsAsFactors = F)
  # Tree
  datt[[state]] <- read.csv(paste0(dirs[i], "/",state, "_TREE.csv"), stringsAsFactors = F)
  # Subplot Condition
  datspc[[state]] <- read.csv(paste0(dirs[i], "/",state, "_SUBP_COND.csv"), stringsAsFactors = F)
}

### Merge data
datsm <- do.call(rbind, dats)
datpm <- do.call(rbind, datp)
datcm <- do.call(rbind, datc)
dattm<- do.call(rbind, datt)
datspcm<- do.call(rbind, datspc)

remove(datt, datp, datc, dats,datspc)

# Merge Subplot & Plot data
df <- merge(datcm[,c("PLT_CN", "CONDID","COND_STATUS_CD","OWNCD", "STDAGE")], datspcm[,c("PLT_CN", "CONDID", "SUBP")], by=c("PLT_CN", "CONDID"))

# Merge Survey & Plot data
datz <- merge(datsm[,c("CN", "ANN_INVENTORY", "STATEAB")], datpm[,c("CN","SRV_CN","INVYR", "COUNTYCD","PLOT", "PLOT_STATUS_CD", "KINDCD", "DESIGNCD", "MANUAL", "SAMP_METHOD_CD", "REMPER", "MEASYEAR", "ELEV", "LAT", "LON", "PREV_PLT_CN", "UNITCD")],  by.y="SRV_CN", by.x="CN", all==TRUE)
colnames(datz)[which(colnames(datz) %in% c("CN", "CN.y"))] <- c("SRV_CN", "PLT_CN")

#confirm each plot record is in data frame only once 
if(max(sort(table(datz$PLT_CN)))!=1){
  print("stop there are duplicated plot records")
}
datz.sp<-datz
```

```{r merge survey, plot, condition & tree data, eval=F}
## select annual inventory
datz <-datz[datz$ANN_INVENTORY=='Y',]; nrow.annual <- nrow(datz)

## select plots where all of the subplots are forested
allspforested <- unique(df$PLT_CN[!(df$PLT_CN %in% subset(aggregate(COND_STATUS_CD~PLT_CN, FUN=function(x){length(x[x!=1])}, df), COND_STATUS_CD>0)$PLT_CN)])
allspforested <- allspforested[allspforested %in% datz$PLT_CN]
datz <- datz[datz$PLT_CN %in% allspforested, ]

#Merge Survey-Plot-Condition & Tree data
dattm.sub <-subset(dattm, PLT_CN %in% datz$PLT_CN)
datz <- merge(datz, dattm.sub[, c("PLT_CN", "CN", "STATECD", "COUNTYCD","TREE", "DIST", "STATUSCD", "DIA", "SPCD","CCLCD", "AGENTCD", "DAMAGE_AGENT_CD1","DAMAGE_AGENT_CD2", "DAMAGE_AGENT_CD3", "TPA_UNADJ")],  by="PLT_CN", all=FALSE)
datz$PLOT.STATEAB <- paste(datz$PLOT, datz$STATEAB, sep=".")

# subset data to only trees greater than 5 inches (12.7 cm) DBH
datz5 <- subset(datz, DIA>=5)

# subset data to only trees within subplot
datz5 <- subset(datz5, DIST<=24)

# remove trees with missing values for TPA count 
datz5 <- datz5[is.na(datz5$TPA_UNADJ)==FALSE, ] ## not sure why missing values occur here
datz5.bak <- datz5

spruce.plots <-unique(datz5[datz5$SPCD == PIEN,"PLT_CN"])
pine.plots <-unique(datz5[datz5$SPCD == PICO,"PLT_CN"])
fir.plots <- unique(datz5[datz5$SPCD == ABLA,"PLT_CN"])
datz5 <- datz5[datz5$PLT_CN %in% c(spruce.plots, pine.plots, fir.plots),]

## subset to recently killed trees
datz5.bak <- datz5
datz5$STATUSCD <- factor(datz5$STATUSCD , levels=c(0:3), labels=c("No Status", "Live", "Dead", "Removed"))
datz5$STATUSCD.2<- ifelse(datz5$STATUSCD=="Dead" & is.na(datz5$AGENTCD) == FALSE, "Recently killed",as.character(datz5$STATUSCD))
datz5 <- datz5[datz5$STATUSCD.2 %in% c("Live", "Recently killed"),]
```

#### Determination of presence/absence of bark beetle activity

For each live tree (>= 12.7 cm DBH), field crews record up to three damaging agents, which are defined as agents that are likely to prevent the tree from surviving >2 years, reduce the growth of the tree in the near term, or negatively affect the tree's marketable products [@burrill_forest_2017].

Cause of death codes are very broad (e.g., "insect" or "disease"). Accuracy of FIA data is commonly assessed using blind checks, where two crews perform independent inventories. Agreement between mortality agent codes recorded in the two inventories is generally >80% [@anderegg_tree_2015]. Active damage is easier to identify, thus the codes for damaging agents are much more specific.

```{r determine presence of BB agents in focal hosts, eval=F}
datz5$WBBB.l <- NA
datz5$WBBB.d <- NA
datz5$WBBB.l <- ifelse(datz5$DAMAGE_AGENT_CD1==bb & datz5$SPCD==ABLA |datz5$DAMAGE_AGENT_CD1 %in% c(wbbb, sfm) & datz5$SPCD == ABLA, 1, 0) 
datz5$WBBB.d <- ifelse(datz5$AGENTCD==10 & datz5$SPCD == ABLA, 1, 0) 
datz5$WBBB <- rowSums(datz5[,c("WBBB.d", "WBBB.l")], na.rm=T)
datz5$WBBB[is.na(datz5$WBBB)==T]<-0

datz5$MPB.l <- NA
datz5$MPB.d <- NA
datz5$MPB.l <- ifelse(datz5$DAMAGE_AGENT_CD1==bb & datz5$SPCD ==PICO | datz5$DAMAGE_AGENT_CD1 ==11006 & datz5$SPCD ==PICO, 1, 0) 
datz5$MPB.d <- ifelse(datz5$AGENTCD==10 & datz5$SPCD ==PICO , 1, 0) 
datz5$MPB <- rowSums(datz5[,c("MPB.d", "MPB.l")], na.rm=T)
datz5$MPB[is.na(datz5$MPB)==T]<-0

datz5$SB.l <- NA
datz5$SB.d <- NA
datz5$SB.l <- ifelse(datz5$DAMAGE_AGENT_CD1==bb & datz5$SPCD == PIEN | datz5$DAMAGE_AGENT_CD1==11009 & datz5$SPCD == PIEN, 1, 0) 
datz5$SB.d <- ifelse(datz5$AGENTCD==10 & datz5$SPCD == PIEN, 1, 0)  
datz5$SB <- rowSums(datz5[,c("SB.d", "SB.l")], na.rm=T)
datz5$SB[is.na(datz5$SB)==T]<-0
```

#### Calculation of stand characteristics
For each plot, we then calculated
1 - basal area by host species
2 - quadratic mean diameter (QMD)
3 - basal area dominance (% total basal area) by species
4 - presence and severity of bark beetle activity (% total basal area) by bark beetle species

```{r stand characteristics, eval=F}
## BA
datz5$BA <- datz5$DIA*datz5$DIA * pi/(4*144) *datz5$TPA_UNADJ # sq ft per acre
datz5$BA <- datz5$BA * 1/10.7639 * 2.47105/1 # m2 per ha
BA <- aggregate(BA~PLT_CN+SPCD, datz5, FUN=sum, na.rm=T)
BA.dat <- dcast(BA, PLT_CN~SPCD, value.var="BA", drop=F)
BA.dat$BA.total <- rowSums(BA.dat[,-1], na.rm=T)
BA.dat$BA.Allhosts <- rowSums(BA.dat[,as.character(c(PICO, PIEN, ABLA))], na.rm=T)
BA.dat$BA.Otherhosts <- rowSums(BA.dat[,as.character(otherhosts)], na.rm=T)
BA.dat <- BA.dat[, c("PLT_CN", PICO, PIEN, ABLA, "BA.total", "BA.Allhosts", "BA.Otherhosts")]
colnames(BA.dat) <- c("PLT_CN", paste0("BA.", c("PICO", "PIEN", "ABLA", "total", "Allhosts", "Otherhosts")))
BA.dat[is.na(BA.dat)==TRUE] <- 0

## Trees per ha
datz5$TPH <- datz5$TPA_UNADJ * 2.47105 # trees per ha
TPH <- aggregate(TPH~PLT_CN+SPCD, datz5, FUN=sum, na.rm=T)
TPH.dat <- dcast(TPH, PLT_CN~SPCD, value.var="TPH", drop=F)
TPH.dat$TPH.total <- rowSums(TPH.dat[,-1], na.rm=T)
TPH.dat$TPH.Allhosts <- rowSums(TPH.dat[,as.character(c(PICO, PIEN, ABLA))], na.rm=T)
TPH.dat <- TPH.dat[, c("PLT_CN", PICO, PIEN, ABLA, "TPH.total", "TPH.Allhosts")]
colnames(TPH.dat) <- c("PLT_CN", paste0("TPH.", c("PICO", "PIEN", "ABLA", "total", "Allhosts")))
TPH.dat[is.na(TPH.dat)==TRUE] <- 0

## QMD
datz5$DIAcm <- datz5$DIA * 2.54 # convert to cm
qmd <- aggregate(DIAcm~PLT_CN+SPCD, datz5, FUN=function(x){sqrt(mean(x*x,na.rm=T))})
qmd.dat<- dcast(qmd, PLT_CN~SPCD , value.var="DIAcm", drop=F)
qmd.dat<- qmd.dat[,c("PLT_CN", PICO, PIEN, ABLA)]
colnames(qmd.dat) <- c("PLT_CN", paste0("QMD.",c("PICO", "PIEN", "ABLA")))
qmd.dat.hosts <- aggregate(DIAcm~PLT_CN, datz5[datz5$SPCD %in% c(PICO, PIEN, ABLA),], FUN=function(x){sqrt(mean(x*x,na.rm=T))})
colnames(qmd.dat.hosts) <- c("PLT_CN", "QMD.Allhosts")
qmd.dat.all <- aggregate(DIAcm~PLT_CN, datz5, FUN=function(x){sqrt(mean(x*x,na.rm=T))})
colnames(qmd.dat.all) <- c("PLT_CN", "QMD.total")
qmd.dat<-merge(qmd.dat, qmd.dat.hosts, by="PLT_CN", all=T)
qmd.dat<-merge(qmd.dat, qmd.dat.all, by="PLT_CN", all=T)
qmd.dat[is.na(qmd.dat)] <- 0

## SDI (additive)
datz5$SDIi <- (datz5$DIA/10)^1.6
sdi <- aggregate(SDIi~PLT_CN+SPCD, datz5, FUN=sum)
sdi.dat<- dcast(sdi, PLT_CN~SPCD , value.var="SDIi", drop=F)
sdi.dat<- sdi.dat[,c("PLT_CN", PICO, PIEN, ABLA)]
colnames(sdi.dat) <- c("PLT_CN", paste0("SDI.",c("PICO", "PIEN", "ABLA")))
sdi.dat[is.na(sdi.dat)] <- 0

## Trees per plot of bark beetle affected trees
notreesBB.dat <- merge(merge(aggregate(MPB~PLT_CN,datz5, FUN=sum, na.rm=T),  aggregate(SB~PLT_CN,datz5, FUN=sum, na.rm=T), by="PLT_CN", all=T), aggregate(WBBB~PLT_CN,datz5, FUN=sum, na.rm=T), by="PLT_CN", all=T)
colnames(notreesBB.dat) <- c("PLT_CN", paste0("stand.", c("MPB", "SB", "WBBB")))
notreesBB.dat$stand.allBBs <- rowSums(notreesBB.dat[,2:4])
notreesBB.dat[is.na(notreesBB.dat)] <- 0

## Total BA of bark beetle affected trees
BABB.dat <- merge(merge(aggregate(MPB*BA~PLT_CN,datz5, FUN=sum, na.rm=T),  aggregate(SB*BA~PLT_CN,datz5, FUN=sum, na.rm=T), by="PLT_CN", all=T), aggregate(WBBB*BA~PLT_CN,datz5, FUN=sum, na.rm=T), by="PLT_CN", all=T)
colnames(BABB.dat) <- c("PLT_CN", paste0("BA.", c("MPB", "SB", "WBBB")))
BABB.dat$BA.allBBs <- rowSums(BABB.dat[,2:4])
BABB.dat[is.na(BABB.dat)] <- 0

df<- unique(datz5[,c("PLT_CN", "PREV_PLT_CN", "PLOT.STATEAB", "INVYR", "ELEV", "LAT", "LON" ),])
df <-merge(df, TPH.dat, by="PLT_CN", all=T)
df <-merge(df, qmd.dat, by="PLT_CN", all=T)
df <-merge(df, BA.dat, by="PLT_CN", all=T)
df <-merge(df, sdi.dat, by="PLT_CN", all=T)
df <- merge(df, notreesBB.dat, by="PLT_CN", all=T)
df <- merge(df, BABB.dat, by="PLT_CN", all=T)
df[is.na(df$PREV_PLT_CN)==TRUE, "PREV_PLT_CN"] <- -9999
df <- na.omit(df)

df$agentSB <- ifelse(df$stand.SB>0, "SB", "absent")
df$agentMPB <- ifelse(df$stand.MPB>0, "MPB", "absent")
df$agentWBBB <- ifelse(df$stand.WBBB>0, "WBBB", "absent")

df$agents <-  do.call(paste, c(df[c("agentSB", "agentMPB", "agentWBBB")],sep="-"))
df$agents <- factor(df$agents, levels=c("absent-absent-absent","absent-MPB-absent","SB-absent-absent", "SB-MPB-absent", "absent-absent-WBBB", "SB-absent-WBBB", "absent-MPB-WBBB", "SB-MPB-WBBB"), labels=c("none", "MPB", "SB", "MPB+SB", "WBBB", "SB+WBBB", "MPB+WBBB", "MPB+SB+WBBB"))

df$nagents <- df$agents
df$nagents <- factor(df$nagents, levels=c("none", "MPB", "SB", "MPB+SB", "WBBB", "SB+WBBB", "MPB+WBBB", "MPB+SB+WBBB"), labels=c(0, 1, 1, 2, 1, 2, 2, 3))

df$hostsPICO <- ifelse(df$TPH.PICO>0, "PICO", "absent")
df$hostsPIEN <- ifelse(df$TPH.PIEN>0, "PIEN", "absent")
df$hostsABLA <- ifelse(df$TPH.ABLA>0, "ABLA", "absent")
df$hosts <-  do.call(paste, c(df[c("hostsPICO", "hostsPIEN", "hostsABLA")],sep="-"))
df$hosts <- factor(df$hosts, levels=c('PICO-absent-absent','absent-absent-ABLA', 'absent-PIEN-absent', 'PICO-PIEN-absent',   'PICO-absent-ABLA', 'absent-PIEN-ABLA', 'PICO-PIEN-ABLA', 'absent-absent-absent'), labels= c('PICO', 'ABLA', 'PIEN', 'PICO+PIEN', 'PICO+ABLA', 'PIEN+ABLA', 'PICO+PIEN+ABLA', 'none'), ordered=TRUE)

df$nhosts <- df$hosts
df$nhosts <- factor(df$nhosts, levels=c('PICO', 'ABLA', 'PIEN', 'PICO+PIEN', 'PICO+ABLA', 'PIEN+ABLA', 'PICO+PIEN+ABLA', 'none'), labels=c(1, 1,1,2,2,2,3,0))

write.csv(df, here("Data/Processed/FIAdat-df.csv"),row.names=F)
```

#### Selection of plots
We selected all plots that were part of the annual inventory and where all subplots were inventoried. 

Within this plots, we characterized stand structure and composition using only live and recently killed (i.e. killed within the past ~10 years) trees greater that 12.7 cm DBH within the subplot.

```{r select plots}
df <- read.csv(here("Data/Processed/FIAdat-df.csv"))

##select most recent inventories
df.recent <- df

df.recent <-df.recent[!(df.recent$PREV_PLT_CN %in% df.recent$PLT_CN), ] # select plots that have not been subsequently sampled

##select inventories conducted within the last 10 years
df.recent <- df.recent[df.recent$INVYR %in% 2010:2019,]
df.recent$LONx <- df.recent$LON
df.recent$LATx <- df.recent$LAT
##select inventories with coordinates located in the Intermountain West
df.recent.sf <- st_as_sf(df.recent, coords = c("LONx", "LATx"), crs = 4326)
df.recent.sf <- st_transform(df.recent.sf,  crs = aea.proj)
states <-st_read(here("Data/Spatial/States/cb_2018_us_state_20m.shp"),quiet=T)
states <- st_transform(states, crs = aea.proj)
df.recent.sf.j.states <- st_join(df.recent.sf, states)
df.recent.sf.j.states<- df.recent.sf.j.states[df.recent.sf.j.states$STUSPS %in% c("AZ", "CO", "ID","MT", "NM", "UT", "WY"),]

df.recent.sf <- df.recent.sf.j.states
df.recent <- df.recent.sf
st_geometry(df.recent) <- NULL

write.csv(df.recent, here("Data/Processed/FIAdat-recent.csv"))
```

```{r merge data, eval=F}
df.recent <- read.csv(here("Data/Processed/FIAdat-recent.csv"))
write.csv(df, here("Data/Processed/FIAdat-df-merge.csv"), row.names=F)
```

```{r reorganize by focal host, eval=F}
df <- read.csv(here("Data/Processed/FIAdat-df-merge.csv"))

formatp <- function(d, host="PIEN", agent="SB"){
  df.p <- d[which(d[, paste0("TPH.", host)]>0),]
  #df.p <- d
  df.p$TPH.host <- df.p[, paste0("TPH.", host)]
  df.p$QMD.host <- df.p[, paste0("QMD.", host)]
  df.p$BA.host <- df.p[, paste0("BA.", host)]

  df.p$stand.BB <- df.p[, paste0("stand.", agent)]
  df.p$BA.BB <- df.p[, paste0("BA.", agent)]
  df.p$affected <- ifelse(df.p$stand.BB>0, "affected", "unaffected")
  df.p$focalhost <- host
  
  df.p$BAD.host <- df.p$BA.host/df.p$BA.total
  df.p$TPHD.host <- df.p$TPH.host/df.p$TPH.total
  #df.p$pressure.BB <- df.p[,paste0("pressure", agent)]
  
  return(df.p)
}

df <- rbind(rbind(formatp(df), formatp(df, host="PICO", agent="MPB")), formatp(df, host="ABLA", agent="WBBB"), formatp(df, host="Allhosts", agent="allBBs"))

### Proportion of total BA affected
df$propTBA <- df$BA.BB/df$BA.total

### Proportion of host BA affected
df$propHBA <- df$BA.BB/df$BA.Allhosts

### Proportion of total trees affected
df$propTTPH <- (df$stand.BB*unique(6.018046)*2.47105)/df$TPH.total

### Proportion of host trees affected
df$propHTPH <- (df$stand.BB*unique(6.018046)*2.47105)/df$TPH.host

### Affected
df$affected01 <- ifelse(df$stand.BB>0, "affected", "unaffected")

write.csv(df, here("Data/Processed/FIAdat-df-merge-re.csv"),row.names=F)
```

## Analyses

```{r import processed data}
df <- read.csv( here("Data/Processed/FIAdat-df-merge-re.csv"))
df$nhostsF <-factor(df$nhosts, levels=1:3, labels=c("one", "two", "three"), ordered=T)
df$hosts <- factor(df$hosts, levels=c("PICO", "PIEN", "ABLA", "PICO+PIEN", "PICO+ABLA", "PIEN+ABLA", "PICO+PIEN+ABLA"), ordered=T)
df$hostsFP <- factor(df$hosts, levels=c("PICO", "PIEN", "ABLA", "PICO+PIEN", "PICO+ABLA", "PIEN+ABLA", "PICO+PIEN+ABLA"), labels=c("PICO", "PIEN", "ABLA", "PICO & PIEN", "PICO & ABLA", "PIEN & ABLA", "PICO, PIEN, & ABLA"), ordered=T)

df$nagentsF <- factor(df$nagents, levels=0:3, ordered=T)
df$agentsF <- factor(df$agents, levels=c("none", "MPB", "SB", "WBBB", "MPB+SB","MPB+WBBB",  "SB+WBBB", "MPB+SB+WBBB"), ordered=T)

df$focalhost <- factor(df$focalhost, levels=c("PICO", "PIEN", "ABLA", "Allhosts"), labels=c("PICO", "PIEN", "ABLA", "Any"), ordered=T)

df$focalagent <- factor(df$focalhost, levels= c("PICO", "PIEN", "ABLA", "Any"), labels=c("MPB", "SB", "WBBB", "Any"), ordered=T)

df$propBA.PICO <- df$BA.PICO / df$BA.total *100
df$propBA.PIEN <- df$BA.PIEN / df$BA.total *100
df$propBA.ABLA <- df$BA.ABLA / df$BA.total *100
```

### Model the suitable stand conditions
Construct random forest models using synthetic minority oversampling technique (SMOTE), an approach for dealing with imbalanced data. The SMOTE approach oversamples the minority class by synthesizing new cases from the minority class. We compared this approach with two other common approaches for dealing with imbalanced data in a random forest framework - balanced and weighted random forests and selected the approach that classified affected plots with the greatest accuracy. 

```{r fit MPB RF model SMOTE, eval=F}
response <- "agentMPB"
vars <- c("BA.PICO", "QMD.PICO", "propBA.PICO") # predictor variables
datBB.c <- df[df$focalhost=="Any",] # dataframe containing response and predictors (here i had to subset it because of how my data was arranged)

splitit <- initial_split(datBB.c, prop=.7, strata=response) # partition data to create test and training datasets stratified by the response class
datz.train <- training(splitit) # create object with training data
datz.test <- testing(splitit) # create object with testing data
datz.train.cv <- vfold_cv(datz.train, strata=response, v=10) # partition training data to allow for cross validation (again stratified by the response class) for optimization of model hyperparameters

# set formula
BBoccurrence_recipe <- recipe(formula(paste(response, "~", paste(vars, collapse = " + "))), datz.train) %>% step_smote(response) # set model preprocessing to include SMOTE to simulate more presence cases

# set sample weights (not used in SMOTE approach)
wts <- 1/(table(datBB.c[,response])/ max(table(datBB.c[,response])))
wts <- wts/sum(wts)

# set model
rf_model <- rand_forest() %>% set_args( trees=tune(), min_n=tune()) %>% set_engine("ranger", importance = "permutation", seed=913, probability=T, num.threads = cores) %>% set_mode("classification")  

# set the workflow
rf_workflow <- workflow() %>% add_recipe(BBoccurrence_recipe) %>% add_model(rf_model)

# tune model
tgrid <- expand.grid(trees = c(100,500), min_n=c(10, 50, 100))
rf_tune_results <- rf_workflow %>% tune_grid(resamples = datz.train.cv,  grid = tgrid, metrics = metric_set(roc_auc, sens, spec))

tuneres <- rf_tune_results %>% collect_metrics() # collect metrics

param_best<- rf_tune_results %>% select_best(metric = "roc_auc") # select best hyperparameters

# Use backward selection to identify important variables
#dfo.vsurf <- VSURF::VSURF(datz.train[,vars], factor(datz.train[,response]), RFimplem="ranger", parallel=T, ntree=param_best$trees, min.node.size=param_best$min_n)
#registerDoSEQ()
#vars.final <- unique(c(vars[dfo.vsurf$varselect.pred]))
vars.final <- vars
BBoccurrence_recipe_final <- recipe(formula(paste(response, "~", paste(vars.final, collapse = " + "))), data=datBB.c) %>% step_smote(response) 
  
rf_model_final <- rand_forest() %>% set_args(trees=param_best$trees, min_n=param_best$min_n, splitrule="gini") %>% set_engine("ranger", importance = "permutation", probability=T, num.threads = cores) %>% set_mode("classification") 

rf_workflow_final <- workflow() %>% add_recipe(BBoccurrence_recipe_final) %>% add_model(rf_model_final)
rf_workflow_final_fit<- rf_workflow_final %>% last_fit(splitit, metrics=metric_set(roc_auc, sens, spec)) #emulates the process where, after determining the best model, the final fit on the entire training set is needed and is then evaluated on the test set. 
test_performance <- rf_workflow_final_fit %>% collect_metrics()
write.csv(test_performance, here(paste0("Results/RF-testperformance-", response, "-occurrence-SMOTE.csv")), row.names=F)
  
# generate a confusion matrix for test set
test_predictions <- rf_workflow_final_fit %>% collect_predictions()
confusion <- test_predictions %>% conf_mat(response,estimate = .pred_class)

write.csv(confusion$table, here(paste0("Results/RF-confusiontable-", response, "-occurrence-SMOTE.csv")), row.names=F)

# variable importance
final_model <- fit(rf_workflow_final, data=datz.train)
ranger_obj <- pull_workflow_fit(final_model)$fit

# generate predictions for entire dataset
x <- datBB.c$PLT_CN
x <- cbind(x, predict(ranger_obj, datBB.c)$predictions[,2])
colnames(x) <- c("PLT_CN", "SBpred")
write.csv(x, here(paste0("Results/RF-pred-", response, "-occurrence-SMOTE.csv")), row.names=F)
          
x <- as.data.frame(ranger_obj$variable.importance)
write.csv(x, here(paste0("Results/RF-vimp-", response, "-occurrence-SMOTE.csv")), row.names=F)
          
# partial dependence
pd <- NULL
for(z in vars.final){
  pdz <- partial(ranger_obj, train=datz.train, pred.var=z, which.class=strsplit(response, split="agent")[[1]][2], prob=T)
  pdz$var <- z
  colnames(pdz) <- c("value","yhat","var")
  pd <- rbind(pd, pdz)
}
write.csv(pd,  here(paste0("Results/RF-partialdependence-", response, "-occurrence-SMOTE.csv")), row.names=F)
```

```{r fit MPB RF model Balanced, eval=F}
response <- "agentMPB"
vars <- c("BA.PICO", "QMD.PICO", "propBA.PICO")
datBB.c <- df[df$focalhost=="Any",]

splitit <- initial_split(datBB.c, prop=.7, strata=response) # partition data to create test and training datasets stratified by the response class
datz.train <- training(splitit)
datz.test <- testing(splitit)
datz.train.cv <- vfold_cv(datz.train, strata=response, v=10) # partition training data to allow for cross validation (again stratified by the response class) for optimization of model hyperparameters

# set formula
BBoccurrence_recipe <- recipe(formula(paste(response, "~", paste(vars, collapse = " + "))), datz.train) 
# set sample weights
wts <- 1/(table(datBB.c[,response])/ max(table(datBB.c[,response])))
wts <- wts/sum(wts)

# set model
rf_model <- rand_forest() %>% set_args( trees=tune(), min_n=tune()) %>% set_engine("ranger", importance = "permutation", seed=913, probability=T, sample.fraction=wts) %>% set_mode("classification")  

# set the workflow
rf_workflow <- workflow() %>% add_recipe(BBoccurrence_recipe) %>% add_model(rf_model)

# tune model
tgrid <- expand.grid(trees = c(100,500), min_n=c(10, 50, 100))
rf_tune_results <- rf_workflow %>% tune_grid(resamples = datz.train.cv,  grid = tgrid, metrics = metric_set(roc_auc, sens, spec))

tuneres <- rf_tune_results %>% collect_metrics() # collect metrics

param_best<- rf_tune_results %>% select_best(metric = "roc_auc") # select best hyperparameters

# Use backward selection to identify important variables
#dfo.vsurf <- VSURF::VSURF(datz.train[,vars], factor(datz.train[,response]), RFimplem="ranger", parallel=T, ntree=param_best$trees, min.node.size=param_best$min_n)
#registerDoSEQ()
#vars.final <- unique(c(vars[dfo.vsurf$varselect.pred]))
vars.final <- vars
BBoccurrence_recipe_final <- recipe(formula(paste(response, "~", paste(vars.final, collapse = " + "))), data=datBB.c)
  
rf_model_final <- rand_forest() %>% set_args(trees=param_best$trees, min_n=param_best$min_n, splitrule="gini") %>% set_engine("ranger", importance = "permutation", probability=T, sample.fraction=wts, num.threads = cores) %>% set_mode("classification") 

rf_workflow_final <- workflow() %>% add_recipe(BBoccurrence_recipe_final) %>% add_model(rf_model_final)
rf_workflow_final_fit<- rf_workflow_final %>% last_fit(splitit, metrics=metric_set(roc_auc, sens, spec)) #emulates the process where, after determining the best model, the final fit on the entire training set is needed and is then evaluated on the test set. 
test_performance <- rf_workflow_final_fit %>% collect_metrics()
write.csv(test_performance, here(paste0("Results/RF-testperformance-", response, "-occurrence-BALANCED.csv")), row.names=F)
  
# generate a confusion matrix for test set
test_predictions <- rf_workflow_final_fit %>% collect_predictions()
confusion <- test_predictions %>% conf_mat(response,estimate = .pred_class)

write.csv(confusion$table, here(paste0("Results/RF-confusiontable-", response, "-occurrence-BALANCED.csv")), row.names=F)

# variable importance
final_model <- fit(rf_workflow_final, data=datz.train)
ranger_obj <- pull_workflow_fit(final_model)$fit

# generate predictions for entire dataset
x <- datBB.c$PLT_CN
x <- cbind(x, predict(ranger_obj, datBB.c)$predictions[,2])
colnames(x) <- c("PLT_CN", "SBpred")
write.csv(x, here(paste0("Results/RF-pred-", response, "-occurrence-BALANCED.csv")), row.names=F)
          
x <- as.data.frame(ranger_obj$variable.importance)
write.csv(x, here(paste0("Results/RF-vimp-", response, "-occurrence-BALANCED.csv")), row.names=F)
          
# partial dependence
pd <- NULL
for(z in vars.final){
  pdz <- partial(ranger_obj, train=datz.train, pred.var=z, which.class=strsplit(response, split="agent")[[1]][2], prob=T)
  pdz$var <- z
  colnames(pdz) <- c("value","yhat","var")
  pd <- rbind(pd, pdz)
}
write.csv(pd,  here(paste0("Results/RF-partialdependence-", response, "-occurrence-BALANCED.csv")), row.names=F)
```

```{r fit MPB RF model Weighted, eval=F}
response <- "agentMPB"
vars <- c("BA.PICO", "QMD.PICO", "propBA.PICO")
datBB.c <- df[df$focalhost=="Any",]

splitit <- initial_split(datBB.c, prop=.7, strata=response) # partition data to create test and training datasets stratified by the response class
datz.train <- training(splitit)
datz.test <- testing(splitit)
datz.train.cv <- vfold_cv(datz.train, strata=response, v=10) # partition training data to allow for cross validation (again stratified by the response class) for optimization of model hyperparameters

# set formula
BBoccurrence_recipe <- recipe(formula(paste(response, "~", paste(vars, collapse = " + "))), datz.train) 
# set sample weights
wts <- 1/(table(datBB.c[,response])/ max(table(datBB.c[,response])))
wts <- wts/sum(wts)

# set model
rf_model <- rand_forest() %>% set_args( trees=tune(), min_n=tune()) %>% set_engine("ranger", importance = "permutation", seed=913, probability=T, class.weights=wts, num.threads = cores) %>% set_mode("classification")  

# set the workflow
rf_workflow <- workflow() %>% add_recipe(BBoccurrence_recipe) %>% add_model(rf_model)

# tune model
tgrid <- expand.grid(trees = c(100,500), min_n=c(10, 50, 100))
rf_tune_results <- rf_workflow %>% tune_grid(resamples = datz.train.cv,  grid = tgrid, metrics = metric_set(roc_auc, sens, spec))

tuneres <- rf_tune_results %>% collect_metrics() # collect metrics

param_best<- rf_tune_results %>% select_best(metric = "roc_auc") # select best hyperparameters

# Use backward selection to identify important variables
#dfo.vsurf <- VSURF::VSURF(datz.train[,vars], factor(datz.train[,response]), RFimplem="ranger", parallel=T, ntree=param_best$trees, min.node.size=param_best$min_n)
#registerDoSEQ()
#vars.final <- unique(c(vars[dfo.vsurf$varselect.pred]))
vars.final <- vars
BBoccurrence_recipe_final <- recipe(formula(paste(response, "~", paste(vars.final, collapse = " + "))), data=datBB.c)
  
rf_model_final <- rand_forest() %>% set_args(trees=param_best$trees, min_n=param_best$min_n, splitrule="gini") %>% set_engine("ranger", importance = "permutation", probability=T, class.weights=wts, num.threads = cores) %>% set_mode("classification") 

rf_workflow_final <- workflow() %>% add_recipe(BBoccurrence_recipe_final) %>% add_model(rf_model_final)
rf_workflow_final_fit<- rf_workflow_final %>% last_fit(splitit, metrics=metric_set(roc_auc, sens, spec)) #emulates the process where, after determining the best model, the final fit on the entire training set is needed and is then evaluated on the test set. 
test_performance <- rf_workflow_final_fit %>% collect_metrics()
write.csv(test_performance, here(paste0("Results/RF-testperformance-", response, "-occurrence-WEIGHTED.csv")), row.names=F)
  
# generate a confusion matrix for test set
test_predictions <- rf_workflow_final_fit %>% collect_predictions()
confusion <- test_predictions %>% conf_mat(response,estimate = .pred_class)

write.csv(confusion$table, here(paste0("Results/RF-confusiontable-", response, "-occurrence-WEIGHTED.csv")), row.names=F)

# variable importance
final_model <- fit(rf_workflow_final, data=datz.train)
ranger_obj <- pull_workflow_fit(final_model)$fit

# generate predictions for entire dataset
x <- datBB.c$PLT_CN
x <- cbind(x, predict(ranger_obj, datBB.c)$predictions[,2])
colnames(x) <- c("PLT_CN", "SBpred")
write.csv(x, here(paste0("Results/RF-pred-", response, "-occurrence-WEIGHTED.csv")), row.names=F)
          
x <- as.data.frame(ranger_obj$variable.importance)
write.csv(x, here(paste0("Results/RF-vimp-", response, "-occurrence-WEIGHTED.csv")), row.names=F)
          
# partial dependence
pd <- NULL
for(z in vars.final){
  pdz <- partial(ranger_obj, train=datz.train, pred.var=z, which.class=strsplit(response, split="agent")[[1]][2], prob=T)
  pdz$var <- z
  colnames(pdz) <- c("value","yhat","var")
  pd <- rbind(pd, pdz)
}
write.csv(pd,  here(paste0("Results/RF-partialdependence-", response, "-occurrence-WEIGHTED.csv")), row.names=F)
```

```{r fit SB RF model SMOTE, eval=F}
response <- "agentSB"
vars <- c("BA.PIEN", "QMD.PIEN", "propBA.PIEN")
datBB.c <- df[df$focalhost=="Any",]

splitit <- initial_split(datBB.c, prop=.7, strata=response) # partition data to create test and training datasets stratified by the response class
datz.train <- training(splitit)
datz.test <- testing(splitit)
datz.train.cv <- vfold_cv(datz.train, strata=response, v=10) # partition training data to allow for cross validation (again stratified by the response class) for optimization of model hyperparameters

# set formula
BBoccurrence_recipe <- recipe(formula(paste(response, "~", paste(vars, collapse = " + "))), datz.train) %>% step_smote(response) # set model preprocessing to include SMOTE to simulate more presence cases

# set sample weights
wts <- 1/(table(datBB.c[,response])/ max(table(datBB.c[,response])))
wts <- wts/sum(wts)

# set model
rf_model <- rand_forest() %>% set_args( trees=tune(), min_n=tune()) %>% set_engine("ranger", importance = "permutation", seed=913, probability=T, num.threads = cores) %>% set_mode("classification")  

# set the workflow
rf_workflow <- workflow() %>% add_recipe(BBoccurrence_recipe) %>% add_model(rf_model)

# tune model
tgrid <- expand.grid(trees = c(100,500), min_n=c(10, 50, 100))
rf_tune_results <- rf_workflow %>% tune_grid(resamples = datz.train.cv,  grid = tgrid, metrics = metric_set(roc_auc, sens, spec))

tuneres <- rf_tune_results %>% collect_metrics() # collect metrics

param_best<- rf_tune_results %>% select_best(metric = "roc_auc") # select best hyperparameters

# Use backward selection to identify important variables
#dfo.vsurf <- VSURF::VSURF(datz.train[,vars], factor(datz.train[,response]), RFimplem="ranger", parallel=T, ntree=param_best$trees, min.node.size=param_best$min_n)
#registerDoSEQ()
#vars.final <- unique(c(vars[dfo.vsurf$varselect.pred]))
vars.final <- vars
BBoccurrence_recipe_final <- recipe(formula(paste(response, "~", paste(vars.final, collapse = " + "))), data=datBB.c) %>% step_smote(response) 
  
rf_model_final <- rand_forest() %>% set_args(trees=param_best$trees, min_n=param_best$min_n, splitrule="gini") %>% set_engine("ranger", importance = "permutation", probability=T, num.threads = cores) %>% set_mode("classification") 

rf_workflow_final <- workflow() %>% add_recipe(BBoccurrence_recipe_final) %>% add_model(rf_model_final)
rf_workflow_final_fit<- rf_workflow_final %>% last_fit(splitit, metrics=metric_set(roc_auc, sens, spec)) #emulates the process where, after determining the best model, the final fit on the entire training set is needed and is then evaluated on the test set. 
test_performance <- rf_workflow_final_fit %>% collect_metrics()
write.csv(test_performance, here(paste0("Results/RF-testperformance-", response, "-occurrence-SMOTE.csv")), row.names=F)
  
# generate a confusion matrix for test set
test_predictions <- rf_workflow_final_fit %>% collect_predictions()
confusion <- test_predictions %>% conf_mat(response,estimate = .pred_class)

write.csv(confusion$table, here(paste0("Results/RF-confusiontable-", response, "-occurrence-SMOTE.csv")), row.names=F)

# variable importance
final_model <- fit(rf_workflow_final, data=datz.train)
ranger_obj <- pull_workflow_fit(final_model)$fit

# generate predictions for entire dataset
x <- datBB.c$PLT_CN
x <- cbind(x, predict(ranger_obj, datBB.c)$predictions[,2])
colnames(x) <- c("PLT_CN", "SBpred")
write.csv(x, here(paste0("Results/RF-pred-", response, "-occurrence-SMOTE.csv")), row.names=F)
          
x <- as.data.frame(ranger_obj$variable.importance)
write.csv(x, here(paste0("Results/RF-vimp-", response, "-occurrence-SMOTE.csv")), row.names=F)
          
# partial dependence
pd <- NULL
for(z in vars.final){
  pdz <- partial(ranger_obj, train=datz.train, pred.var=z, which.class=strsplit(response, split="agent")[[1]][2], prob=T)
  pdz$var <- z
  colnames(pdz) <- c("value","yhat","var")
  pd <- rbind(pd, pdz)
}
write.csv(pd,  here(paste0("Results/RF-partialdependence-", response, "-occurrence-SMOTE.csv")), row.names=F)
```

```{r fit SB RF model Balanced, eval=F}
response <- "agentSB"
vars <- c("BA.PIEN", "QMD.PIEN", "propBA.PIEN")
datBB.c <- df[df$focalhost=="Any",]

splitit <- initial_split(datBB.c, prop=.7, strata=response) # partition data to create test and training datasets stratified by the response class
datz.train <- training(splitit)
datz.test <- testing(splitit)
datz.train.cv <- vfold_cv(datz.train, strata=response, v=10) # partition training data to allow for cross validation (again stratified by the response class) for optimization of model hyperparameters

# set formula
BBoccurrence_recipe <- recipe(formula(paste(response, "~", paste(vars, collapse = " + "))), datz.train) 
# set sample weights
wts <- 1/(table(datBB.c[,response])/ max(table(datBB.c[,response])))
wts <- wts/sum(wts)

# set model
rf_model <- rand_forest() %>% set_args( trees=tune(), min_n=tune()) %>% set_engine("ranger", importance = "permutation", seed=913, probability=T, sample.fraction=wts, num.threads = cores) %>% set_mode("classification")  

# set the workflow
rf_workflow <- workflow() %>% add_recipe(BBoccurrence_recipe) %>% add_model(rf_model)

# tune model
tgrid <- expand.grid(trees = c(100,500), min_n=c(10, 50, 100))
rf_tune_results <- rf_workflow %>% tune_grid(resamples = datz.train.cv,  grid = tgrid, metrics = metric_set(roc_auc, sens, spec))

tuneres <- rf_tune_results %>% collect_metrics() # collect metrics

param_best<- rf_tune_results %>% select_best(metric = "roc_auc") # select best hyperparameters

# Use backward selection to identify important variables
#dfo.vsurf <- VSURF::VSURF(datz.train[,vars], factor(datz.train[,response]), RFimplem="ranger", parallel=T, ntree=param_best$trees, min.node.size=param_best$min_n)
#registerDoSEQ()
#vars.final <- unique(c(vars[dfo.vsurf$varselect.pred]))
vars.final <- vars
BBoccurrence_recipe_final <- recipe(formula(paste(response, "~", paste(vars.final, collapse = " + "))), data=datBB.c)
  
rf_model_final <- rand_forest() %>% set_args(trees=param_best$trees, min_n=param_best$min_n, splitrule="gini") %>% set_engine("ranger", importance = "permutation", probability=T, sample.fraction=wts, num.threads = cores) %>% set_mode("classification") 

rf_workflow_final <- workflow() %>% add_recipe(BBoccurrence_recipe_final) %>% add_model(rf_model_final)
rf_workflow_final_fit<- rf_workflow_final %>% last_fit(splitit, metrics=metric_set(roc_auc, sens, spec)) #emulates the process where, after determining the best model, the final fit on the entire training set is needed and is then evaluated on the test set. 
test_performance <- rf_workflow_final_fit %>% collect_metrics()
write.csv(test_performance, here(paste0("Results/RF-testperformance-", response, "-occurrence-BALANCED.csv")), row.names=F)
  
# generate a confusion matrix for test set
test_predictions <- rf_workflow_final_fit %>% collect_predictions()
confusion <- test_predictions %>% conf_mat(response,estimate = .pred_class)

write.csv(confusion$table, here(paste0("Results/RF-confusiontable-", response, "-occurrence-BALANCED.csv")), row.names=F)

# variable importance
final_model <- fit(rf_workflow_final, data=datz.train)
ranger_obj <- pull_workflow_fit(final_model)$fit

# generate predictions for entire dataset
x <- datBB.c$PLT_CN
x <- cbind(x, predict(ranger_obj, datBB.c)$predictions[,2])
colnames(x) <- c("PLT_CN", "SBpred")
write.csv(x, here(paste0("Results/RF-pred-", response, "-occurrence-BALANCED.csv")), row.names=F)
          
x <- as.data.frame(ranger_obj$variable.importance)
write.csv(x, here(paste0("Results/RF-vimp-", response, "-occurrence-BALANCED.csv")), row.names=F)
          
# partial dependence
pd <- NULL
for(z in vars.final){
  pdz <- partial(ranger_obj, train=datz.train, pred.var=z, which.class=strsplit(response, split="agent")[[1]][2], prob=T)
  pdz$var <- z
  colnames(pdz) <- c("value","yhat","var")
  pd <- rbind(pd, pdz)
}
write.csv(pd,  here(paste0("Results/RF-partialdependence-", response, "-occurrence-BALANCED.csv")), row.names=F)
```

```{r fit SB RF model Weighted, eval=F}
response <- "agentSB"
vars <- c("BA.PIEN", "QMD.PIEN", "propBA.PIEN")

datBB.c <- df[df$focalhost=="Any",]

splitit <- initial_split(datBB.c, prop=.7, strata=response) # partition data to create test and training datasets stratified by the response class
datz.train <- training(splitit)
datz.test <- testing(splitit)
datz.train.cv <- vfold_cv(datz.train, strata=response, v=10) # partition training data to allow for cross validation (again stratified by the response class) for optimization of model hyperparameters

# set formula
BBoccurrence_recipe <- recipe(formula(paste(response, "~", paste(vars, collapse = " + "))), datz.train) 
# set sample weights
wts <- 1/(table(datBB.c[,response])/ max(table(datBB.c[,response])))
wts <- wts/sum(wts)

# set model
rf_model <- rand_forest() %>% set_args( trees=tune(), min_n=tune()) %>% set_engine("ranger", importance = "permutation", seed=913, probability=T, class.weights=wts, num.threads = cores) %>% set_mode("classification")  

# set the workflow
rf_workflow <- workflow() %>% add_recipe(BBoccurrence_recipe) %>% add_model(rf_model)

# tune model
tgrid <- expand.grid(trees = c(100,500), min_n=c(10, 50, 100))
rf_tune_results <- rf_workflow %>% tune_grid(resamples = datz.train.cv,  grid = tgrid, metrics = metric_set(roc_auc, sens, spec))

tuneres <- rf_tune_results %>% collect_metrics() # collect metrics

param_best<- rf_tune_results %>% select_best(metric = "roc_auc") # select best hyperparameters

# Use backward selection to identify important variables
#dfo.vsurf <- VSURF::VSURF(datz.train[,vars], factor(datz.train[,response]), RFimplem="ranger", parallel=T, ntree=param_best$trees, min.node.size=param_best$min_n)
#registerDoSEQ()
#vars.final <- unique(c(vars[dfo.vsurf$varselect.pred]))
vars.final <- vars
BBoccurrence_recipe_final <- recipe(formula(paste(response, "~", paste(vars.final, collapse = " + "))), data=datBB.c)
  
rf_model_final <- rand_forest() %>% set_args(trees=param_best$trees, min_n=param_best$min_n, splitrule="gini") %>% set_engine("ranger", importance = "permutation", probability=T, class.weights=wts, num.threads = cores) %>% set_mode("classification") 

rf_workflow_final <- workflow() %>% add_recipe(BBoccurrence_recipe_final) %>% add_model(rf_model_final)
rf_workflow_final_fit<- rf_workflow_final %>% last_fit(splitit, metrics=metric_set(roc_auc, sens, spec)) #emulates the process where, after determining the best model, the final fit on the entire training set is needed and is then evaluated on the test set. 
test_performance <- rf_workflow_final_fit %>% collect_metrics()
write.csv(test_performance, here(paste0("Results/RF-testperformance-", response, "-occurrence-WEIGHTED.csv")), row.names=F)
  
# generate a confusion matrix for test set
test_predictions <- rf_workflow_final_fit %>% collect_predictions()
confusion <- test_predictions %>% conf_mat(response,estimate = .pred_class)

write.csv(confusion$table, here(paste0("Results/RF-confusiontable-", response, "-occurrence-WEIGHTED.csv")), row.names=F)

# variable importance
final_model <- fit(rf_workflow_final, data=datz.train)
ranger_obj <- pull_workflow_fit(final_model)$fit

# generate predictions for entire dataset
x <- datBB.c$PLT_CN
x <- cbind(x, predict(ranger_obj, datBB.c)$predictions[,2])
colnames(x) <- c("PLT_CN", "SBpred")
write.csv(x, here(paste0("Results/RF-pred-", response, "-occurrence-WEIGHTED.csv")), row.names=F)
          
x <- as.data.frame(ranger_obj$variable.importance)
write.csv(x, here(paste0("Results/RF-vimp-", response, "-occurrence-WEIGHTED.csv")), row.names=F)
          
# partial dependence
pd <- NULL
for(z in vars.final){
  pdz <- partial(ranger_obj, train=datz.train, pred.var=z, which.class=strsplit(response, split="agent")[[1]][2], prob=T)
  pdz$var <- z
  colnames(pdz) <- c("value","yhat","var")
  pd <- rbind(pd, pdz)
}
write.csv(pd,  here(paste0("Results/RF-partialdependence-", response, "-occurrence-WEIGHTED.csv")), row.names=F)
```

```{r fit WBBB RF model SMOTE, eval=F}
response <- "agentWBBB"
vars <- c("BA.ABLA", "QMD.ABLA", "propBA.ABLA")
datBB.c <- df[df$focalhost=="Any",]

splitit <- initial_split(datBB.c, prop=.7, strata=response) # partition data to create test and training datasets stratified by the response class
datz.train <- training(splitit)
datz.test <- testing(splitit)
datz.train.cv <- vfold_cv(datz.train, strata=response, v=10) # partition training data to allow for cross validation (again stratified by the response class) for optimization of model hyperparameters

# set formula
BBoccurrence_recipe <- recipe(formula(paste(response, "~", paste(vars, collapse = " + "))), datz.train) %>% step_smote(response) # set model preprocessing to include SMOTE to simulate more presence cases

# set sample weights
wts <- 1/(table(datBB.c[,response])/ max(table(datBB.c[,response])))
wts <- wts/sum(wts)

# set model
rf_model <- rand_forest() %>% set_args( trees=tune(), min_n=tune()) %>% set_engine("ranger", importance = "permutation", seed=913, probability=T, num.threads = cores) %>% set_mode("classification")  

# set the workflow
rf_workflow <- workflow() %>% add_recipe(BBoccurrence_recipe) %>% add_model(rf_model)

# tune model
tgrid <- expand.grid(trees = c(100,500), min_n=c(10, 50, 100))
rf_tune_results <- rf_workflow %>% tune_grid(resamples = datz.train.cv,  grid = tgrid, metrics = metric_set(roc_auc, sens, spec))

tuneres <- rf_tune_results %>% collect_metrics() # collect metrics

param_best<- rf_tune_results %>% select_best(metric = "roc_auc") # select best hyperparameters

# Use backward selection to identify important variables
#dfo.vsurf <- VSURF::VSURF(datz.train[,vars], factor(datz.train[,response]), RFimplem="ranger", parallel=T, ntree=param_best$trees, min.node.size=param_best$min_n)
#registerDoSEQ()
#vars.final <- unique(c(vars[dfo.vsurf$varselect.pred]))
vars.final <- vars
BBoccurrence_recipe_final <- recipe(formula(paste(response, "~", paste(vars.final, collapse = " + "))), data=datBB.c) %>% step_smote(response) 
  
rf_model_final <- rand_forest() %>% set_args(trees=param_best$trees, min_n=param_best$min_n, splitrule="gini") %>% set_engine("ranger", importance = "permutation", probability=T, num.threads = cores) %>% set_mode("classification") 

rf_workflow_final <- workflow() %>% add_recipe(BBoccurrence_recipe_final) %>% add_model(rf_model_final)
rf_workflow_final_fit<- rf_workflow_final %>% last_fit(splitit, metrics=metric_set(roc_auc, sens, spec)) #emulates the process where, after determining the best model, the final fit on the entire training set is needed and is then evaluated on the test set. 
test_performance <- rf_workflow_final_fit %>% collect_metrics()
write.csv(test_performance, here(paste0("Results/RF-testperformance-", response, "-occurrence-SMOTE.csv")), row.names=F)
  
# generate a confusion matrix for test set
test_predictions <- rf_workflow_final_fit %>% collect_predictions()
confusion <- test_predictions %>% conf_mat(response,estimate = .pred_class)

write.csv(confusion$table, here(paste0("Results/RF-confusiontable-", response, "-occurrence-SMOTE.csv")), row.names=F)

# variable importance
final_model <- fit(rf_workflow_final, data=datz.train)
ranger_obj <- pull_workflow_fit(final_model)$fit

# generate predictions for entire dataset
x <- datBB.c$PLT_CN
x <- cbind(x, predict(ranger_obj, datBB.c)$predictions[,2])
colnames(x) <- c("PLT_CN", "SBpred")
write.csv(x, here(paste0("Results/RF-pred-", response, "-occurrence-SMOTE.csv")), row.names=F)
          
x <- as.data.frame(ranger_obj$variable.importance)
write.csv(x, here(paste0("Results/RF-vimp-", response, "-occurrence-SMOTE.csv")), row.names=F)
          
# partial dependence
pd <- NULL
for(z in vars.final){
  pdz <- partial(ranger_obj, train=datz.train, pred.var=z, which.class=strsplit(response, split="agent")[[1]][2], prob=T)
  pdz$var <- z
  colnames(pdz) <- c("value","yhat","var")
  pd <- rbind(pd, pdz)
}
write.csv(pd,  here(paste0("Results/RF-partialdependence-", response, "-occurrence-SMOTE.csv")), row.names=F)
```

```{r fit WBBB RF model Balanced, eval=F}
response <- "agentWBBB"
vars <- c("BA.ABLA", "QMD.ABLA", "propBA.ABLA")
datBB.c <- df[df$focalhost=="Any",]

splitit <- initial_split(datBB.c, prop=.7, strata=response) # partition data to create test and training datasets stratified by the response class
datz.train <- training(splitit)
datz.test <- testing(splitit)
datz.train.cv <- vfold_cv(datz.train, strata=response, v=10) # partition training data to allow for cross validation (again stratified by the response class) for optimization of model hyperparameters

# set formula
BBoccurrence_recipe <- recipe(formula(paste(response, "~", paste(vars, collapse = " + "))), datz.train) 
# set sample weights
wts <- 1/(table(datBB.c[,response])/ max(table(datBB.c[,response])))
wts <- wts/sum(wts)

# set model
rf_model <- rand_forest() %>% set_args( trees=tune(), min_n=tune()) %>% set_engine("ranger", importance = "permutation", seed=913, probability=T, sample.fraction=wts, num.threads = cores) %>% set_mode("classification")  

# set the workflow
rf_workflow <- workflow() %>% add_recipe(BBoccurrence_recipe) %>% add_model(rf_model)

# tune model
tgrid <- expand.grid(trees = c(100,500), min_n=c(10, 50, 100))
rf_tune_results <- rf_workflow %>% tune_grid(resamples = datz.train.cv,  grid = tgrid, metrics = metric_set(roc_auc, sens, spec))

tuneres <- rf_tune_results %>% collect_metrics() # collect metrics

param_best<- rf_tune_results %>% select_best(metric = "roc_auc") # select best hyperparameters

# Use backward selection to identify important variables
#dfo.vsurf <- VSURF::VSURF(datz.train[,vars], factor(datz.train[,response]), RFimplem="ranger", parallel=T, ntree=param_best$trees, min.node.size=param_best$min_n)
#registerDoSEQ()
#vars.final <- unique(c(vars[dfo.vsurf$varselect.pred]))
vars.final <- vars
BBoccurrence_recipe_final <- recipe(formula(paste(response, "~", paste(vars.final, collapse = " + "))), data=datBB.c)
  
rf_model_final <- rand_forest() %>% set_args(trees=param_best$trees, min_n=param_best$min_n, splitrule="gini") %>% set_engine("ranger", importance = "permutation", probability=T, sample.fraction=wts, num.threads = cores) %>% set_mode("classification") 

rf_workflow_final <- workflow() %>% add_recipe(BBoccurrence_recipe_final) %>% add_model(rf_model_final)
rf_workflow_final_fit<- rf_workflow_final %>% last_fit(splitit, metrics=metric_set(roc_auc, sens, spec)) #emulates the process where, after determining the best model, the final fit on the entire training set is needed and is then evaluated on the test set. 
test_performance <- rf_workflow_final_fit %>% collect_metrics()
write.csv(test_performance, here(paste0("Results/RF-testperformance-", response, "-occurrence-BALANCED.csv")), row.names=F)
  
# generate a confusion matrix for test set
test_predictions <- rf_workflow_final_fit %>% collect_predictions()
confusion <- test_predictions %>% conf_mat(response,estimate = .pred_class)

write.csv(confusion$table, here(paste0("Results/RF-confusiontable-", response, "-occurrence-BALANCED.csv")), row.names=F)

# variable importance
final_model <- fit(rf_workflow_final, data=datz.train)
ranger_obj <- pull_workflow_fit(final_model)$fit

# generate predictions for entire dataset
x <- datBB.c$PLT_CN
x <- cbind(x, predict(ranger_obj, datBB.c)$predictions[,2])
colnames(x) <- c("PLT_CN", "SBpred")
write.csv(x, here(paste0("Results/RF-pred-", response, "-occurrence-BALANCED.csv")), row.names=F)
          
x <- as.data.frame(ranger_obj$variable.importance)
write.csv(x, here(paste0("Results/RF-vimp-", response, "-occurrence-BALANCED.csv")), row.names=F)
          
# partial dependence
pd <- NULL
for(z in vars.final){
  pdz <- partial(ranger_obj, train=datz.train, pred.var=z, which.class=strsplit(response, split="agent")[[1]][2], prob=T)
  pdz$var <- z
  colnames(pdz) <- c("value","yhat","var")
  pd <- rbind(pd, pdz)
}
write.csv(pd,  here(paste0("Results/RF-partialdependence-", response, "-occurrence-BALANCED.csv")), row.names=F)
```

```{r fit WBBB RF model Weighted, eval=F}
response <- "agentWBBB"
vars <- c("BA.ABLA", "QMD.ABLA", "propBA.ABLA")
datBB.c <- df[df$focalhost=="Any",]

splitit <- initial_split(datBB.c, prop=.7, strata=response) # partition data to create test and training datasets stratified by the response class
datz.train <- training(splitit)
datz.test <- testing(splitit)
datz.train.cv <- vfold_cv(datz.train, strata=response, v=10) # partition training data to allow for cross validation (again stratified by the response class) for optimization of model hyperparameters

# set formula
BBoccurrence_recipe <- recipe(formula(paste(response, "~", paste(vars, collapse = " + "))), datz.train) 
# set sample weights
wts <- 1/(table(datBB.c[,response])/ max(table(datBB.c[,response])))
wts <- wts/sum(wts)

# set model
rf_model <- rand_forest() %>% set_args( trees=tune(), min_n=tune()) %>% set_engine("ranger", importance = "permutation", seed=913, probability=T, class.weights=wts, num.threads = cores) %>% set_mode("classification")  

# set the workflow
rf_workflow <- workflow() %>% add_recipe(BBoccurrence_recipe) %>% add_model(rf_model)

# tune model
tgrid <- expand.grid(trees = c(100,500), min_n=c(10, 50, 100))
rf_tune_results <- rf_workflow %>% tune_grid(resamples = datz.train.cv,  grid = tgrid, metrics = metric_set(roc_auc, sens, spec))

tuneres <- rf_tune_results %>% collect_metrics() # collect metrics

param_best<- rf_tune_results %>% select_best(metric = "roc_auc") # select best hyperparameters

# Use backward selection to identify important variables
#dfo.vsurf <- VSURF::VSURF(datz.train[,vars], factor(datz.train[,response]), RFimplem="ranger", parallel=T, ntree=param_best$trees, min.node.size=param_best$min_n)
#registerDoSEQ()
#vars.final <- unique(c(vars[dfo.vsurf$varselect.pred]))
vars.final <- vars
BBoccurrence_recipe_final <- recipe(formula(paste(response, "~", paste(vars.final, collapse = " + "))), data=datBB.c)
  
rf_model_final <- rand_forest() %>% set_args(trees=param_best$trees, min_n=param_best$min_n, splitrule="gini") %>% set_engine("ranger", importance = "permutation", probability=T, class.weights=wts, num.threads = cores) %>% set_mode("classification") 

rf_workflow_final <- workflow() %>% add_recipe(BBoccurrence_recipe_final) %>% add_model(rf_model_final)
rf_workflow_final_fit<- rf_workflow_final %>% last_fit(splitit, metrics=metric_set(roc_auc, sens, spec)) #emulates the process where, after determining the best model, the final fit on the entire training set is needed and is then evaluated on the test set. 
test_performance <- rf_workflow_final_fit %>% collect_metrics()
write.csv(test_performance, here(paste0("Results/RF-testperformance-", response, "-occurrence-WEIGHTED.csv")), row.names=F)
  
# generate a confusion matrix for test set
test_predictions <- rf_workflow_final_fit %>% collect_predictions()
confusion <- test_predictions %>% conf_mat(response,estimate = .pred_class)

write.csv(confusion$table, here(paste0("Results/RF-confusiontable-", response, "-occurrence-WEIGHTED.csv")), row.names=F)

# variable importance
final_model <- fit(rf_workflow_final, data=datz.train)
ranger_obj <- pull_workflow_fit(final_model)$fit

# generate predictions for entire dataset
x <- datBB.c$PLT_CN
x <- cbind(x, predict(ranger_obj, datBB.c)$predictions[,2])
colnames(x) <- c("PLT_CN", "SBpred")
write.csv(x, here(paste0("Results/RF-pred-", response, "-occurrence-WEIGHTED.csv")), row.names=F)
          
x <- as.data.frame(ranger_obj$variable.importance)
write.csv(x, here(paste0("Results/RF-vimp-", response, "-occurrence-WEIGHTED.csv")), row.names=F)
          
# partial dependence
pd <- NULL
for(z in vars.final){
  pdz <- partial(ranger_obj, train=datz.train, pred.var=z, which.class=strsplit(response, split="agent")[[1]][2], prob=T)
  pdz$var <- z
  colnames(pdz) <- c("value","yhat","var")
  pd <- rbind(pd, pdz)
}
write.csv(pd,  here(paste0("Results/RF-partialdependence-", response, "-occurrence-WEIGHTED.csv")), row.names=F)
```

```{r determine suitable stands}
MPBpred <- read.csv(here("Results/RF-pred-agentMPB-occurrence-SMOTE.csv"))
SBpred <- read.csv(here("Results/RF-pred-agentSB-occurrence-SMOTE.csv"))
WBBBpred <- read.csv(here("Results/RF-pred-agentWBBB-occurrence-SMOTE.csv"))

BBpred <- merge(merge(MPBpred, SBpred, by="PLT_CN"), WBBBpred, by="PLT_CN")
colnames(BBpred) <- c("PLT_CN", "MPBpred", "SBpred", "WBBBpred")

threshold <-0.5
BBpred$MPBsuitable <- ifelse(BBpred$MPBpred > threshold, "MPB", "absent")
BBpred$SBsuitable <- ifelse(BBpred$SBpred > threshold, "SB", "absent")
BBpred$WBBBsuitable <- ifelse(BBpred$WBBBpred >threshold, "WBBB", "absent")

BBpred$agentsuitable <-  do.call(paste, c(BBpred[c("SBsuitable", "MPBsuitable", "WBBBsuitable")],sep="-"))
BBpred$agentsuitable <- factor(BBpred$agentsuitable, levels=c("absent-absent-absent","absent-MPB-absent","SB-absent-absent", "SB-MPB-absent", "absent-absent-WBBB", "SB-absent-WBBB", "absent-MPB-WBBB", "SB-MPB-WBBB"), labels=c("none", "MPB", "SB", "MPB+SB", "WBBB", "SB+WBBB", "MPB+WBBB", "MPB+SB+WBBB"))

BBpred$suitablehosts <- factor(BBpred$agentsuitable, levels=c("none", "MPB", "SB", "WBBB", "MPB+SB",  "MPB+WBBB", "SB+WBBB",  "MPB+SB+WBBB"), ordered=T)

```

# Results
## Is co-occurrence of multiple hosts common?
```{r describe frequency of hosts and agents, eval=T}
## Hosts
hosts <- df[!df$focalhost=="Any",] %>% group_by(focalhost) %>% summarise(n = n())%>%mutate(freq = n / sum(n))
hostgroups <- df[df$focalhost=="Any",] %>% group_by(hosts) %>% summarise(n = n())%>%mutate(freq = n / sum(n))
hostgroups$hosts <- factor(hostgroups$hosts, levels=hostgroups$hosts, labels=c("PICO", "PIEN", "ABLA", "PICO\n&\nPIEN", "PICO\n&\nABLA", "PIEN\n&\nABLA", "PICO,\nPIEN,\n&\nABLA"))


nhosts <- df[df$focalhost=="Any",] %>% group_by(nhosts) %>% summarise(n = n())%>%mutate(freq = n / sum(n))


## Affected hosts
affectedhosts <- df[!df$focalhost=="Any",] %>% group_by(focalhost, affected) %>% summarise(n = n())%>% mutate(freq = prop.table(n))
affectednhosts <- df[df$focalhost=="Any",] %>% group_by(nhosts, affected) %>% summarise(n = n())%>% mutate(freq = prop.table(n))
affectednhosts<- affectednhosts[affectednhosts$affected=="affected", ]
affectednhosts<- affectednhosts[order(affectednhosts$freq, decreasing=T),]

affectedhostgroups <- df[df$focalhost=="Any",] %>% group_by(hosts, affected) %>% summarise(n = n())%>% mutate(freq = prop.table(n))
affectedhostgroups<- affectedhostgroups[affectedhostgroups$affected=="affected", ]
affectedhostgroups<- affectedhostgroups[order(affectedhostgroups$freq, decreasing=T),]

## Agents given host presence
agents <- df[!df$focalhost=="Any",] %>% group_by(focalagent, affected) %>% summarise(n = n())%>%
  mutate(freq = n / sum(n))
PICOwMPB <- as.numeric(round(agents[agents$focalagent=="MPB" & agents$affected=="affected", "freq"]*100, 0))
PIENwSB <- as.numeric(round(agents[agents$focalagent=="SB" & agents$affected=="affected", "freq"]*100, 0))
ABLAwWBBB<- as.numeric(round(agents[agents$focalagent=="WBBB" & agents$affected=="affected", "freq"]*100, 0))

## Agents given presence of any agent
agentso <- df[!df$focalhost=="Any" & df$affected=="affected",] %>% group_by(focalagent) %>% summarise(n = n())%>%
  mutate(freq = n / sum(n))

agentsbyhosts <- df[!df$focalhost=="Any",] %>% group_by(focalagent, affected) %>% summarise(n = n())%>% mutate(freq = prop.table(n))

p1 <- ggplot(df[df$focalhost=="Any",], aes(x=hosts, fill=interaction(hosts, affected))) + geom_bar(width=0.75, stat="count", col="black")+ylab("number of plots")+theme(axis.text.x = element_text(angle = 45, hjust=1,vjust=1),legend.position = "none", legend.title=element_blank())+scale_fill_manual(values=c(c("#8c510a", "#bf812d", "#dfc27d", "#80cdc1", "#35978f", "#01665e", "#003c30"), adjust_transparency(c("#8c510a", "#bf812d", "#dfc27d", "#80cdc1", "#35978f", "#01665e", "#003c30"), alpha=0.5)))

Fig.file <- here("Results/Figures/Figure-PresencebyHostcombos.jpg")
jpeg(Fig.file, width=fig.width1.5,height=2.5,units="in", res=300)
p1
whatever <- dev.off()
```

```{r}
gghostgroups <- ggplot(hostgroups, aes(x=hosts, y=freq, fill=hosts))+geom_bar(stat="identity")+scale_fill_manual(values=c("#8c510a", "#bf812d", "#dfc27d", "#80cdc1", "#35978f", "#01665e", "#003c30"))+theme(legend.position="none")+xlab("")+ylab("frequency")

ggsave( here("Results/Figures/FigureHostFreq.jpg"), plot=gghostgroups,   width=fig.width1,height=fig.width1*0.75,units="in")
```

Yes, 66% (n=5,850) FIA plots had at least two host species present. Subalpine fir was most likely to occur with other hosts (50% of stands), followed by Engelmann spruce (45% stands), and lodgepole pine (36% of stands) (Fig. \@ref(fig:FigHostFreq)).

```{r FigHostFreq, fig.cap = ".", out.width = "322.56pt"}
knitr::include_graphics( here("Results/Figures/FigureHostFreq.jpg"))
```

## Is co-occurrence of the stands conditions suitable for multiple bark beetle species common?

20% of stands were suitable for more than one bark beetle species. Conditions suitable for WBBB were most likely to co-occur with conditions suitable for another bark beetle (17% of stands)

```{r determine co-occurrence of suitable stands}
bbo.dat<- merge(BBpred, df, id.vars="PLT_CN", all=T)
bbo.dat <- bbo.dat[bbo.dat$focalagent=="Any",]

suitablehostgroups <- bbo.dat[bbo.dat$focalagent=="Any",]%>% group_by(suitablehosts) %>% summarise(n = n())%>%mutate(freq = n / sum(n))

bbo.dat$hostsFPshort<- bbo.dat$hosts
bbo.dat$hostsFPshort <- factor(bbo.dat$hosts, levels=levels(bbo.dat$hosts), labels=c("PICO", "PIEN", "ABLA", "PICO\n&\nPIEN", "PICO\n&\nABLA", "PIEN\n&\nABLA", "PICO,\nPIEN,\n&\nABLA"))
bbo.dat$agentsFplongrev <- bbo.dat$agentsF
bbo.dat$agentsFplongrev <- factor(bbo.dat$agentsFplongrev, levels=rev(levels( bbo.dat$agentsFplong)))

bbo.sub <- bbo.dat[bbo.dat$focalhost=="Any",]
bbo.sub <- bbo.dat[!bbo.dat$suitablehosts=="none",]

bbo.sub$suitablehostsP <- factor(bbo.sub$suitablehosts, levels=levels(bbo.sub$suitablehosts)[-1], labels=c("PICO", "PIEN", "ABLA", "PICO\n&\nPIEN", "PICO\n&\nABLA", "PIEN\n&\nABLA", "PICO,\nPIEN,\n&\nABLA"))

ggfreq <- ggplot(bbo.sub, aes(x=suitablehostsP,fill=suitablehostsP))+geom_bar()+theme(legend.title = element_blank())+xlab("hosts")+scale_fill_manual(values=c("#8c510a", "#bf812d", "#dfc27d", "#80cdc1", "#35978f", "#01665e", "#003c30"))+theme(legend.position="none")

ggsave( here("Results/Figures/FigureSuitable.jpg"), plot=ggfreq,width=fig.width1,height=fig.width1*0.75,units="in")
```

(Fig. \@ref(fig:FigureSuitable)).

```{r FigureSuitable, fig.cap = ".", out.width = "322.56pt"}
knitr::include_graphics( here("Results/Figures/FigureSuitable.jpg"))
```


## Is occurrence or severity cumulative bark beetle mortality greater in stands with multiple hosts?

```{r occurrence by suitable hosts}

dfpred <- merge(BBpred, df, id.vars="PLT_CN", all=T)
dfpred$suitablehosts <- factor(dfpred$suitablehosts, levels=levels(dfpred$suitablehosts)[-1], labels=c("PICO", "PIEN", "ABLA", "PICO+PIEN", "PICO+ABLA", "PIEN+ABLA", "PICO+PIEN+ABLA"))
mpb <- as.data.frame(table(dfpred[dfpred$focalagent=="MPB","affected"], dfpred[dfpred$focalagent=="MPB","suitablehosts"]))
sb <- as.data.frame(table(dfpred[dfpred$focalagent=="SB","affected"], dfpred[dfpred$focalagent=="SB","suitablehosts"]))
wbbb <- as.data.frame(table(dfpred[dfpred$focalagent=="WBBB","affected"], dfpred[dfpred$focalagent=="WBBB","suitablehosts"]))
any<- as.data.frame(table(dfpred[dfpred$focalagent=="Any","affected"], dfpred[dfpred$focalagent=="Any","suitablehosts"]))

results <- NULL
for(j in c("PICO+PIEN",  "PICO+ABLA", "PIEN+ABLA",  "PICO+PIEN+ABLA")){
  anyj <- any[any$Var2==j,]
  mpbj <- mpb[mpb$Var2==j,]
  sbj <- sb[sb$Var2==j,]
  wbbbj <- wbbb[wbbb$Var2==j,]
  
  x <- prop.test(x=c(mpbj[1,3],anyj[1,3]), n=c(mpbj[1,3]+mpbj[2,3], anyj[1,3]+anyj[2,3]))

  res <- data.frame(suitablehosts=NA, barkbeetle=NA, X=NA, p=NA, prop1=NA, prop2 =NA, lower=NA, upper=NA)
  res$suitablehosts <-j
  res$barkbeetle <- "MPB"
  res$X <- x$statistic
  res$p <- x$p.value
  res$prop1 <- x$estimate[1]
  res$prop2 <- x$estimate[2]
  res$lower <- x$conf.in[1]
  res$upper <- x$conf.in[2]
  x <-NULL
  results <- rbind(results, res)
    
  x <- prop.test(x=c(sbj[1,3],anyj[1,3]), n=c(sbj[1,3]+sbj[2,3], anyj[1,3]+anyj[2,3]))

  res <- data.frame(suitablehosts=NA, barkbeetle=NA, X=NA, p=NA, prop1=NA, prop2 =NA, lower=NA, upper=NA)
  res$suitablehosts <-j
  res$barkbeetle <- "SB"
  res$X <- x$statistic
  res$p <- x$p.value
  res$prop1 <- x$estimate[1]
  res$prop2 <- x$estimate[2]
  res$lower <- x$conf.in[1]
  res$upper <- x$conf.in[2]
  x <-NULL
  results <- rbind(results, res)
  
   x <- prop.test(x=c(wbbbj[1,3],anyj[1,3]), n=c(wbbbj[1,3]+wbbbj[2,3], anyj[1,3]+anyj[2,3]), alternative="less")

  res <- data.frame(suitablehosts=NA, barkbeetle=NA, X=NA, p=NA, prop1=NA, prop2 =NA, lower=NA, upper=NA)
  res$suitablehosts <-j
  res$barkbeetle <- "WBBB"
  res$X <- x$statistic
  res$p <- x$p.value
  res$prop1 <- x$estimate[1]
  res$prop2 <- x$estimate[2]
  res$lower <- x$conf.in[1]
  res$upper <- x$conf.in[2]
  x <-NULL
  results <- rbind(results, res)
}

results$p <- round(results$p,3)

x <- dfpred[is.na(dfpred$suitablehosts)==FALSE,]
x <- x[x$suitablehosts %in% c("PICO+PIEN",  "PICO+ABLA", "PIEN+ABLA",  "PICO+PIEN+ABLA"),]
x[x$suitablehosts == "PICO+PIEN" & x$focalagent=="WBBB","affected"]<- 0
x[x$suitablehosts == "PICO+ABLA" & x$focalagent=="SB","affected"]<- 0
x[x$suitablehosts == "PIEN+ABLA" & x$focalagent=="MPB","affected"]<- 0

xx <- x %>% group_by(suitablehosts,focalagent) %>% count(affected)
xxx <- x %>% group_by(suitablehosts) %>% count()

xxxx <- merge(xx, xxx, by="suitablehosts")
xxxx$prop <- xxxx$n.x/xxxx$n.y
xxxx <- xxxx[xxxx$affected=="affected",]
xxxx <- xxxx[,c(1,2,6)]
colnames(xxxx) <- c("suitablehosts", "barkbeetle", "prop")

resultsx <- merge(results, xxxx, id.vars=c("suitablehosts", "barkbeetle"), all=T)
resultsx$barkbeetle <- factor(resultsx$barkbeetle, levels=c("MPB", 'SB', "WBBB", "Any"), ordered=T)
resultsx <- resultsx[is.na(resultsx$prop)==FALSE,]
resultsx$suitablehosts <- factor(resultsx$suitablehosts, levels=c("PICO+PIEN",  "PICO+ABLA", "PIEN+ABLA",  "PICO+PIEN+ABLA"), labels=c("PICO & PIEN",  "PICO & ABLA", "PIEN & ABLA",  "PICO, PIEN, & ABLA"), ordered=T)
resultsx$pplot <- ifelse(resultsx$p<0.05, "*", "")
resultsx$pplot[is.na(resultsx$pplot) ==TRUE] <- ""


ggoccurrence <- ggplot(resultsx, aes(x=barkbeetle,y=prop, fill=barkbeetle))+geom_bar(stat="identity")+theme(legend.title = element_blank())+geom_text(aes(label=pplot), vjust=-0.25,size=6)+facet_grid(.~suitablehosts, scales="free_x", space="free_x")+xlab("bark beetle species")+scale_fill_manual(values=c(p1col[1:3], gray(0.3)))+theme(legend.position = "none")+ylab("proportion of plots")

ggsave( here("Results/Figures/FigureOccurrencebySuitablehosts.jpg"), plot=ggoccurrence,  width=fig.width2, height=fig.width1*0.66,units="in")

```

Given suitable stand conditions for multiple agents, the probability of occurrence  of any agent was significantly greater than the probability of a single agent \@ref(fig:FigureSuitable).
```{r FigOccurrence, fig.cap = "Severity",  out.width = "504.8pt"}
knitr::include_graphics( here("Results/Figures/FigureOccurrencebySuitablehosts.jpg"))
```

Given suitable stand conditions for multiple agents, is the severity of cumulative bark beetle-driven tree mortality greater in stands with multiple hosts?

In stands suitable for all three hosts, cumulative mortality was significantly greater than mortality by a single agent. \@ref(fig:FigSeverity). When stand conditions were suitable for only two bark beetles, the severity of cumulative tree mortality was driven by the most common agent (MPB > SB > WBBB) and was not significantly different than the cummualtive mortality.

```{r severity by suitable hosts}
dfpred <- merge(BBpred, df, id.vars="PLT_CN", all=T)
dfpred$suitablehosts <- factor(dfpred$suitablehosts, levels=levels(dfpred$suitablehosts)[-1], labels=c("PICO", "PIEN", "ABLA", "PICO+PIEN", "PICO+ABLA", "PIEN+ABLA", "PICO+PIEN+ABLA"))

mpb <- dfpred[dfpred$focalagent=="MPB" & dfpred$suitablehosts %in% c("PICO+PIEN",  "PICO+ABLA",   "PICO+PIEN+ABLA"), ]
sb <- as.data.frame(table(dfpred[dfpred$focalagent=="SB","affected"], dfpred[dfpred$focalagent=="SB","suitablehosts"]))
wbbb <- as.data.frame(table(dfpred[dfpred$focalagent=="WBBB","affected"], dfpred[dfpred$focalagent=="WBBB","suitablehosts"]))
any<- as.data.frame(table(dfpred[dfpred$focalagent=="Any","affected"], dfpred[dfpred$focalagent=="Any","suitablehosts"]))


dfpred <- dfpred[dfpred$suitablehosts %in% c("PICO+PIEN",  "PICO+ABLA", "PIEN+ABLA",  "PICO+PIEN+ABLA"), ]

dfpred <- dfpred[dfpred$affected01=="affected",]


results <- NULL
for(j in c("PICO+PIEN",  "PICO+ABLA", "PIEN+ABLA",  "PICO+PIEN+ABLA")){

  x <- kruskal.test(propTBA~focalagent, data=dfpred[dfpred$suitablehosts ==j  & dfpred$focalagent %in% c('Any', 'MPB'),])
  
  res <- data.frame(suitablehosts=NA, barkbeetle=NA, X=NA, p=NA)
  res$suitablehosts <-j
  res$barkbeetle <- "MPB"
  res$X <- x$statistic
  res$p <- x$p.value
  x <-NULL
  results <- rbind(results, res)
    
 
    x <- kruskal.test(propTBA~focalagent, data=dfpred[dfpred$suitablehosts ==j  & dfpred$focalagent %in% c('Any', 'SB'),])
  
  res <- data.frame(suitablehosts=NA, barkbeetle=NA, X=NA, p=NA)
  res$suitablehosts <-j
  res$barkbeetle <- "SB"
  res$X <- x$statistic
  res$p <- x$p.value
  x <-NULL
  results <- rbind(results, res)
  
      x <- kruskal.test(propTBA~focalagent, data=dfpred[dfpred$suitablehosts ==j  & dfpred$focalagent %in% c('Any', 'WBBB'),])
  
  res <- data.frame(suitablehosts=NA, barkbeetle=NA, X=NA, p=NA)
  res$suitablehosts <-j
  res$barkbeetle <- "WBBB"
  res$X <- x$statistic
  res$p <- x$p.value
  x <-NULL
  results <- rbind(results, res)
  
}

results$pplot <- ifelse(results$p<0.05, "*", NA)

dfpred$pplot <- NA
for(j in c("PICO+PIEN",  "PICO+ABLA", "PIEN+ABLA",  "PICO+PIEN+ABLA")){
  
  x <- dfpred[dfpred$suitablehosts ==j  & dfpred$focalagent == 'MPB',]
  xplt <- x[x$propTBA==max(x$propTBA), "PLT_CN"][1]
  dfpred[dfpred$suitablehosts ==j  & dfpred$focalagent == 'MPB' &dfpred$PLT_CN==xplt, ]$pplot <- results[results$suitablehosts==j & results$barkbeetle=='MPB', "pplot"]
  
    x <- dfpred[dfpred$suitablehosts ==j  & dfpred$focalagent == 'SB',]
  xplt <- x[x$propTBA==max(x$propTBA), "PLT_CN"][1]
  dfpred[dfpred$suitablehosts ==j  & dfpred$focalagent == 'SB' &dfpred$PLT_CN==xplt, ]$pplot <- results[results$suitablehosts==j & results$barkbeetle=='SB', "pplot"]
  
    x <- dfpred[dfpred$suitablehosts ==j  & dfpred$focalagent == 'WBBB',]
  xplt <- x[x$propTBA==max(x$propTBA), "PLT_CN"][1]
  dfpred[dfpred$suitablehosts ==j  & dfpred$focalagent == 'WBBB' & dfpred$PLT_CN==xplt, ]$pplot <- results[results$suitablehosts==j & results$barkbeetle=='WBBB', "pplot"]
    
}

dfpred <- dfpred[!(dfpred$suitablehosts == "PICO+PIEN" & dfpred$focalagent=="WBBB"),]
dfpred <- dfpred[!(dfpred$suitablehosts == "PICO+ABLA" & dfpred$focalagent=="SB"),]
dfpred <- dfpred[!(dfpred$suitablehosts == "PIEN+ABLA" & dfpred$focalagent=="MPB"),]
dfpred$suitablehostsP <- factor(dfpred$suitablehosts, levels=c("PICO+PIEN",  "PICO+ABLA", "PIEN+ABLA",  "PICO+PIEN+ABLA"), labels=c("PICO & PIEN",  "PICO & ABLA", "PIEN & ABLA",  "PICO, PIEN, & ABLA"), ordered=T)

ggseverity <- ggplot(dfpred, aes(x=focalagent, y=propTBA*100, fill=focalagent, colour=focalagent))+geom_boxplot(notch=T)+facet_grid(.~suitablehostsP, scales="free_x", space="free_x")+xlab("bark beetle species")+scale_fill_manual(values=adjust_transparency(c(p1col[1:3], gray(0.3)), 0.5))+scale_colour_manual(values=c(p1col[1:3], gray(0.3)))+theme(legend.position = "none")+ylim(1,110)+geom_text(aes(label=pplot), vjust=-0.1,size=9, col="black")+ylab("Severity (% BA affected)")

ggsave(here("Results/Figures/FigureSevertitybySuitablehosts.jpg"), plot=ggseverity, width=fig.width2,height=fig.width1*0.66,units="in")


```

```{r FigSeverity, fig.cap = "Severity", out.width = "504.8pt"}
knitr::include_graphics( here("Results/Figures/FigureSevertitybySuitablehosts.jpg"))
```

## Given suitable stand conditions, is co-occurrence of multiple agents common?

Not really, only 21.3% (n=461) of stands suitable for multiple agents were affected by multiple agents. When multiple agents occur, the most commonly occurring agents was MPB (n=341), followed by SB (n=317) and WBBB (n=308). The most commonly occurring combinations of agents was MPB and SB (33.2% of cases; n=153), followed by MPB and WBBB (31.2% of cases; n=144) and then SB and WBBB (26% of case; n=120). The combination of all three agents was rare (9.5% of cases; n=44).

```{r determine co-occurrence of agents by hosts}
dfpred <- merge(BBpred, df, id.vars="PLT_CN", all=T)
dfpred <- dfpred[!dfpred$agentsuitable=="none",]

dfpred[dfpred$focalagent=="Any" &dfpred$suitablehosts %in% c("MPB+SB+WBBB",  "SB+WBBB", "MPB+WBBB", "MPB+SB")& dfpred$agentsF %in% c("MPB+SB+WBBB",  "SB+WBBB", "MPB+WBBB", "MPB+SB") ,]  %>% group_by( agentsF) %>% summarise(n = n())%>% mutate(freq = n / sum(n))


dfpred$suitablehostsF <-dfpred$suitablehosts
dfpred$suitablehostsF <- factor(dfpred$suitablehosts, levels=levels(dfpred$suitablehosts)[-1], labels=c("PICO", "PIEN", "ABLA", "PICO\n&\nPIEN", "PICO\n&\nABLA", "PIEN\n&\nABLA", "PICO,\nPIEN,\n&\nABLA"))
dfpred$agentsFplongrev <- factor(dfpred$agents,levels=c("MPB+SB+WBBB", "SB+WBBB", "MPB+WBBB", "MPB+SB", "WBBB", "SB", "MPB", "none"), labels=c("MPB, SB, & WBBB", "SB & WBBB", "MPB & WBBB", "MPB & SB", "WBBB", "SB", "MPB", "none"), ordered=T)


dfpred[dfpred$focalagent=="Any" & dfpred$suitablehostsF %in% c( "PICO\n&\nPIEN", "PICO\n&\nABLA", "PIEN\n&\nABLA", "PICO,\nPIEN,\n&\nABLA"),]  %>% summarise(n = n())

MPBx <- dfpred[dfpred$focalagent=="Any" & dfpred$suitablehostsF %in% c( "PICO\n&\nPIEN", "PICO\n&\nABLA", "PICO,\nPIEN,\n&\nABLA") & dfpred$agentsF %in% c("MPB+SB+WBBB",  "MPB+WBBB", "MPB+SB") ,]  %>% group_by(suitablehostsF, agentsFplongrev) %>% summarise(n = n())%>% mutate(freq = n / sum(n))
sum(MPBx$n)
sum(MPBx$n)/nrow(dfpred[dfpred$suitablehostsF %in% c( "PICO\n&\nPIEN", "PICO\n&\nABLA", "PICO,\nPIEN,\n&\nABLA"),])

SBx <- dfpred[dfpred$focalagent=="Any" & dfpred$suitablehostsF %in% c( "PICO\n&\nPIEN", "PIEN\n&\nABLA", "PICO,\nPIEN,\n&\nABLA") & dfpred$agentsF %in% c("MPB+SB+WBBB",  "SB+WBBB", "MPB+SB") ,]  %>% group_by(suitablehostsF, agentsFplongrev) %>% summarise(n = n())%>% mutate(freq = n / sum(n))
sum(SBx$n)
sum(SBx$n)/nrow(dfpred[dfpred$suitablehostsF %in% c( "PICO\n&\nPIEN", "PIEN\n&\nABLA", "PICO,\nPIEN,\n&\nABLA"),])

WBBBx <- dfpred[dfpred$focalagent=="Any" & dfpred$suitablehostsF %in% c( "PIEN\n&\nABLA", "PICO\n&\nABLA", "PICO,\nPIEN,\n&\nABLA") & dfpred$agentsF %in% c("MPB+SB+WBBB",  "SB+WBBB", "MPB+WBBB") ,]  %>% group_by(suitablehostsF, agentsFplongrev) %>% summarise(n = n())%>% mutate(freq = n / sum(n))
sum(WBBBx$n)
sum(WBBBx$n)/nrow(dfpred[dfpred$suitablehostsF %in% c( "PIEN\n&\nABLA", "PICO\n&\nABLA", "PICO,\nPIEN,\n&\nABLA"),])



### 
table(dfpred$suitablehostsF, dfpred$agents)
x <- dfpred[dfpred$focalhost=="Any" & dfpred$suitablehostsF %in% c("PICO\n&\nPIEN", "PICO\n&\nABLA", "PIEN\n&\nABLA", "PICO,\nPIEN,\n&\nABLA") &  !dfpred$agentsFplongrev =="none",]  %>% group_by(suitablehostsF, agentsFplongrev) %>% summarise(n = n())%>% mutate(freq = n / sum(n))

xPICO <-x[x$suitablehostsF %in% c("PICO\n&\nPIEN", "PICO\n&\nABLA",  "PICO,\nPIEN,\n&\nABLA"),]
#

## Agents given presence of any agent
co <- dfpred[!dfpred$focalhost=="Any" ,]  %>% group_by(suitablehostsF, agentsFplongrev) %>% summarise(n = n())%>% mutate(freq = n / sum(n))

co[co$agentsFplongrev %in% c("MPB, SB, & WBBB", "SB & WBBB", "MPB & WBBB", "MPB & SB") & co$suitablehostsF %in% c("PICO\n&\nPIEN", "PICO\n&\nABLA", "PIEN\n&\nABLA", "PICO,\nPIEN,\n&\nABLA"),]


ggAgentsbySuitablehosts <- ggplot(dfpred[dfpred$focalhost=="Any",], aes(x=suitablehostsF,fill=agentsFplongrev))+geom_bar()+theme(legend.title = element_blank())+scale_fill_manual(values=p2col)+theme(axis.title.x=element_blank())

ggsave(here("Results/Figures/Figure-AgentsbySuitablehosts.jpg"), plot=ggAgentsbySuitablehosts , width=fig.width1.5,height=fig.width1*0.75,units="in")
```

```{r FigCoOccurrence, fig.cap = "Co-occurrence",  out.width = "504.8pt", eval=F}
knitr::include_graphics( here("Results/Figures/Figure-AgentsbySuitablehosts.jpg"))
```

##  Is severity greater in stands with multiple agents?
```{r multiple agents}
library(rcompanion)
dfpred <- merge(BBpred, df, id.vars="PLT_CN", all=T)
dfpred <- dfpred[!dfpred$suitablehosts == "none", ]
dfpred <- dfpred[dfpred$affected01=="affected",]

dfpred$suitablehosts <- factor(dfpred$suitablehosts, levels=levels(dfpred$suitablehosts)[-1], labels=c("PICO", "PIEN", "ABLA", "PICO+PIEN", "PICO+ABLA", "PIEN+ABLA", "PICO+PIEN+ABLA"))

#dfpred <- dfpred[!(dfpred$suitablehosts=="PICO" & dfpred$agentsF %in% c("SB", "WBBB", "MPB+SB", "MPB+WBBB", "SB+WBBB", "MPB+SB+WBBB")),]

#dfpred <- dfpred[!(dfpred$suitablehosts=="PIEN" & dfpred$agentsF %in% c("MPB", "WBBB", "MPB+SB", "MPB+WBBB", "SB+WBBB", "MPB+SB+WBBB")),]

#dfpred <- dfpred[!(dfpred$suitablehosts=="ABLA" & dfpred$agentsF %in% c("MPB", "SB", "MPB+SB", "MPB+WBBB", "SB+WBBB", "MPB+SB+WBBB")),]

dfpred <- dfpred[dfpred$suitablehosts %in% c("PICO+PIEN",  "PICO+ABLA", "PIEN+ABLA",  "PICO+PIEN+ABLA"), ]

dfpred <- dfpred[!(dfpred$suitablehosts=="PICO+PIEN" & dfpred$agentsF %in% c("WBBB", "MPB+WBBB", "SB+WBBB", "MPB+SB+WBBB")),]

dfpred <- dfpred[!(dfpred$suitablehosts=="PICO+ABLA" & dfpred$agentsF %in% c("SB", "MPB+SB", "SB+WBBB", "MPB+SB+WBBB")),]

dfpred <- dfpred[!(dfpred$suitablehosts=="PIEN+ABLA" & dfpred$agentsF %in% c("MPB", "MPB+SB", "MPB+WBBB", "MPB+SB+WBBB")),]

dfpred <-dfpred[dfpred$focalagent=="Any",]

results <- NULL
  dfsub <- dfpred[dfpred$suitablehosts =="PICO+PIEN"  & dfpred$agents %in% c("MPB", "SB","MPB+SB"),]
  dfsub$agents <- as.factor(as.character(dfsub$agents))
  x <- kruskal.test(propTBA~agents, data=dfsub)
  res <- data.frame(agentsF= c("MPB", "SB","MPB+SB"), p=NA)
  DT <- dunnTest(propTBA~agents, data=dfsub,method="bh")
  res <- rcompanion::cldList(P.unadj ~ Comparison, data = DT$res, threshold = 0.1)
  res$suitablehosts <- "PICO+PIEN"

  res <- merge(res, dfsub %>% group_by(agents) %>% summarise(median =median(propTBA), propTBA=max(propTBA)), by.x="Group", by.y="agents")
  res$Letter2 <- c("b", "c", "a")
  results <- rbind(results, res)
  
  dfsub <- dfpred[dfpred$suitablehosts == "PICO+ABLA"  & dfpred$agentsF %in% c("MPB", "WBBB","MPB+WBBB"),]
  dfsub$agentsF <- as.factor(as.character(dfsub$agentsF))
  x <- kruskal.test(propTBA~agentsF, data=dfsub)
  DT <- dunnTest(propTBA~agentsF, data=dfsub,method="bh")
  res <- cldList(P.unadj ~ Comparison, data = DT$res, threshold = 0.05)
  res$suitablehosts <- "PICO+ABLA"
  res <- merge(res, dfsub %>% group_by(agents) %>% summarise(median =median(propTBA), propTBA=max(propTBA)), by.x="Group", by.y="agents")
  res$Letter2 <- c("b", "c", "a")
  results <- rbind(results, res)
  
  dfsub <- dfpred[dfpred$suitablehosts == "PIEN+ABLA"  & dfpred$agentsF %in% c("SB", "WBBB","SB+WBBB"),]
  dfsub$agentsF <- as.factor(as.character(dfsub$agentsF))
  x <- kruskal.test(propTBA~agentsF, data=dfsub)
  DT <- dunnTest(propTBA~agentsF, data=dfsub,method="bh")
  res <- cldList(P.unadj ~ Comparison, data = DT$res, threshold = 0.05)
  res$suitablehosts <- "PIEN+ABLA"
  res <- merge(res, dfsub %>% group_by(agents) %>% summarise(median =median(propTBA), propTBA=max(propTBA)), by.x="Group", by.y="agents")
  res$Letter2 <- c("b", "c", "a")
  results <- rbind(results, res)
  
  dfsub <- dfpred[dfpred$suitablehosts == "PICO+PIEN+ABLA",]
  dfsub$agentsF <- as.factor(as.character(dfsub$agentsF))
  x <- kruskal.test(propTBA~agentsF, data=dfsub)
  DT <- dunnTest(propTBA~agentsF, data=dfsub,method="bh")
  res <- cldList(P.unadj ~ Comparison, data = DT$res, threshold = 0.05)
  res$suitablehosts <- "PICO+PIEN+ABLA"
  res <- merge(res, dfsub %>% group_by(agents) %>% summarise(median =median(propTBA), propTBA=max(propTBA)), by.x="Group", by.y="agents")
  res <- res[order(res$median),]
  res$Letter2 <- c("a", "ab", "abc", "b", "c", "d", "d")
  
  results <- rbind(results, res)
  results$agentsF <- results$Group
  
  
results$suitablehosts <- factor(results$suitablehosts,
levels=c("PICO+PIEN", "PICO+ABLA", "PIEN+ABLA", "PICO+PIEN+ABLA"), labels=c("PICO & PIEN", "PICO & ABLA", "PIEN & ABLA", "PICO, PIEN, & ABLA"), ordered=T)
dfpred$suitablehosts <- factor(dfpred$suitablehosts, levels=c("PICO+PIEN", "PICO+ABLA", "PIEN+ABLA", "PICO+PIEN+ABLA"), labels=c("PICO & PIEN", "PICO & ABLA", "PIEN & ABLA", "PICO, PIEN, & ABLA"), ordered=T)

dfpred$agentsF <- factor(dfpred$agentsF,
levels=c("MPB", "SB", "WBBB", "MPB+SB", "MPB+WBBB", "SB+WBBB", "MPB+SB+WBBB"), labels=c("MPB", "SB", "WBBB", "MPB\n&\nSB", "MPB\n&\nWBBB", "SB\n&\nWBBB", "MPB,\nSB,\n&\nWBBB"), ordered=T)
results$agentsF <- factor(results$agentsF,
levels=c("MPB", "SB", "WBBB", "MPB+SB", "MPB+WBBB", "SB+WBBB", "MPB+SB+WBBB"), labels=c("MPB", "SB", "WBBB", "MPB\n&\nSB", "MPB\n&\nWBBB", "SB\n&\nWBBB", "MPB,\nSB,\n&\nWBBB"), ordered=T)


ggmultipleseverity <- ggplot(dfpred[dfpred$focalagent=="Any",], aes(x=agentsF,y=propTBA*100, fill=agentsF))+geom_boxplot(notch=F)+facet_grid(.~suitablehosts, scales="free_x", space = "free_x")+theme(legend.position="none")+scale_fill_manual(values=rev(p2col)[-1])+ylab("Severity (% basal area)")+xlab("")+ylim(0,110)+geom_text(data=results, aes(label=Letter2), vjust=-1,size=4.5, col="black")+theme(axis.text.x=element_blank(), axis.title.x=element_blank(), axis.ticks = element_blank(), plot.margin = unit(c(4.5,4.5,0,4.5), "pt"))

ggmultipelcount<- ggplot(dfpred[dfpred$focalagent=="Any",], aes(x=agentsF, fill=agentsF))+geom_bar()+facet_grid(.~suitablehosts, scales="free", space = "free_x")+theme(legend.position="none")+scale_fill_manual(values=rev(p2col)[-1])+xlab("")+ylab("frequency")+theme(strip.background = element_blank(), strip.text.x = element_blank(), plot.margin = unit(c(3.5,4.5,0,4.5), "pt"))

ggmulti <- ggmultipleseverity + ggmultipelcount +plot_layout(ncol=1, heights=c(1,0.5))
ggsave(here("Results/Figures/FigureSeverityMultiple.jpg"), plot=ggmulti  , width=fig.width2,height=fig.width1.5,units="in")

ggmultipleseverity <- ggplot(dfpred[dfpred$focalagent=="Any",], aes(x=agentsF,y=propTBA*100, fill=agentsF))+geom_boxplot(notch=F)+facet_grid(.~suitablehosts, scales="free_x", space = "free_x")+theme(legend.position="none")+scale_fill_manual(values=rev(p2col)[-1])+ylab("Severity (% basal area)")+xlab("Bark beetle species present")+ylim(0,110)+geom_text(data=results, aes(label=Letter2), vjust=-1,size=4.5, col="black")

ggsave(here("Results/Figures/FigureHotSpotSeverity.jpg"), plot=ggmultipleseverity, width=fig.width2,height=fig.width1*0.75,units="in")

```

Generally, yes. 

When plots contained two tree species susceptible to bark beetles, the presence of both bark beetle species increased tree mortality relative to presence of only one bark beetle species (Fig. \@ref(fig:FigHotSpotSeverity)). The increase was greatest for stands that contained both MPB and SB; the median severity of plots with both MPB and SB was 33.7 percentage points greater than MPB alone and 38.3 percentage points greater than SB alone. The median severity of plots with both MPB and WBBB was 7.0 percentage points greater than MPB alone and 13.6 percentage points greater than WBBB alone. The median severity of plots with both SB and WBBB was 14.7 percentage points greater than SB alone and 19.8 percentage points greater than WBBB alone.

Given stand conditions that made all three tree species susceptible to bark beetles, the highest rates of mortality were in plots where both MPB and SB present; whether or not WBBB was also present did not affect mortality severity (~1 percentage point difference in median severity; Fig. \@ref(fig:FigHotSpotSeverity)). 

Plots with both SB and WBBB experience similar mortality to plots


The median severity of plots with all three agents was 16.2 percentage points greater than only MPB and WBBB and 27.4% percentage points greater than plots with SB and WBBB. 

The median severity of plots with all three agents was most similar to plots affected by both 


The median severity of plots with all three agents was 27.0 percentage points greater than MPB alone, 34.2 percentage points greater than SB alone, and 32.0% percentage points greater than WBBB alone. 


```{r FigHotSpotSeverity, fig.cap = "The severity of bark beetle mortality in plots with multiple tree species susceptible to bark beetles (columns) by the combinatin of bark beetle species present. Letters above boxes indicate significant (p < 0.05) differences between groups as determined by a Dunn test, a nonparametric rank sum test. The bottom and top limits of each box are the lower and upper quartiles, respectively; the thick black line within the box is the median; error bars equal 1.5 times the interquartile range; and points denote outliers, values outside 1.5 times the interquartile range.",  out.width = "504.8pt"}
knitr::include_graphics( here("Results/Figures/FigureHotSpotSeverity.jpg"))
```


# Discussion

# References

<div id="refs"></div>

## Supplement
### Random Forest Modeling
```{r plot confusion matrices}
MPBct <- read.csv(here("Results/RF-confusiontable-agentMPB-occurrence-SMOTE.csv"))
SBct <- read.csv(here("Results/RF-confusiontable-agentSB-occurrence-SMOTE.csv"))
WBBBct <- read.csv(here("Results/RF-confusiontable-agentWBBB-occurrence-SMOTE.csv"))

BBct <- data.frame(agent=c("MPB", "SB", "WBBB"), sensitivity=c(MPBct[2,2]/sum(MPBct[,2]), SBct[2,2]/sum(SBct[,2]), WBBBct[2,2]/sum(WBBBct[,2])), accuracy= c((MPBct[2,2]+MPBct[1,1])/sum(MPBct), (SBct[2,2]+SBct[1,1])/sum(SBct), (WBBBct[2,2]+WBBBct[1,1])/sum(WBBBct)))
BBct$approach <- "SMOTE"
BBct1  <- BBct


MPBct <- read.csv(here("Results/RF-confusiontable-agentMPB-occurrence-BALANCED.csv"))
SBct <- read.csv(here("Results/RF-confusiontable-agentSB-occurrence-BALANCED.csv"))
WBBBct <- read.csv(here("Results/RF-confusiontable-agentWBBB-occurrence-BALANCED.csv"))

BBct <- data.frame(agent=c("MPB", "SB", "WBBB"), sensitivity=c(MPBct[2,2]/sum(MPBct[,2]), SBct[2,2]/sum(SBct[,2]), WBBBct[2,2]/sum(WBBBct[,2])), accuracy= c((MPBct[2,2]+MPBct[1,1])/sum(MPBct), (SBct[2,2]+SBct[1,1])/sum(SBct), (WBBBct[2,2]+WBBBct[1,1])/sum(WBBBct)))
BBct$approach <- "Balanced"
BBct2  <- BBct

MPBct <- read.csv(here("Results/RF-confusiontable-agentMPB-occurrence-WEIGHTED.csv"))
SBct <- read.csv(here("Results/RF-confusiontable-agentSB-occurrence-WEIGHTED.csv"))
WBBBct <- read.csv(here("Results/RF-confusiontable-agentWBBB-occurrence-WEIGHTED.csv"))

BBct <- data.frame(agent=c("MPB", "SB", "WBBB"), sensitivity=c(MPBct[2,2]/sum(MPBct[,2]), SBct[2,2]/sum(SBct[,2]), WBBBct[2,2]/sum(WBBBct[,2])), accuracy= c((MPBct[2,2]+MPBct[1,1])/sum(MPBct), (SBct[2,2]+SBct[1,1])/sum(SBct), (WBBBct[2,2]+WBBBct[1,1])/sum(WBBBct)))
BBct$approach <- "Weighted"
BBct3  <- BBct


BBct <- rbind(rbind(BBct1, BBct2), BBct3)

ggconfused <- ggplot(BBct, aes(x=agent, y=sensitivity, fill=approach))+geom_bar(stat="identity", position="dodge")+theme(legend.position = "none") + ggplot(BBct, aes(x=agent, y=accuracy, fill=approach))+geom_bar(stat="identity", position="dodge")+plot_layout(nrow=2, guides="collect")


ggsave(here("Results/Figures/Confusion.jpg"), plot=ggconfused, width=fig.width1,height=fig.width1,units="in")
```

```{r confusionFig}
knitr::include_graphics(here("Results/Figures/Confusion.jpg"))
```



```{r FigPartial,  fig.cap = "A caption", out.width = "504.8pt"}
MPBpp <- read.csv(here("Results/RF-partialdependence-agentMPB-occurrence-SMOTE.csv"))
MPBpp$focalagent <- "MPB"
SBpp <- read.csv(here("Results/RF-partialdependence-agentSB-occurrence-SMOTE.csv"))
SBpp$focalagent <- "SB"
WBBBpp <- read.csv(here("Results/RF-partialdependence-agentWBBB-occurrence-SMOTE.csv"))
WBBBpp$focalagent <- "WBBB"

ppdat <- rbind(rbind(MPBpp, SBpp), WBBBpp)
ppdat$var[ppdat$var %in% paste0("BA.", c("PICO", "PIEN", "ABLA"))] <- "BA"
ppdat$var[ppdat$var %in% paste0("QMD.", c("PICO", "PIEN", "ABLA"))] <- "QMD"
ppdat$var[ppdat$var %in% paste0("propBA.", c("PICO", "PIEN", "ABLA"))] <- "propBA"

x <- df[!df$focalagent=="Any",]
x$propBA <- x$BA.host/x$BA.total
x <- x[,c("QMD.host", "propBA", "BA.host", "focalagent", "affected01")]
x$affected01 <- ifelse(x$affected01=="affected", 1, 0)

xm <- melt(x, id.vars=c("focalagent", "affected01"))
colnames(xm) <- c("focalagent", "affected01", "var", "value")
xm$var <- factor(xm$var, levels=c("QMD.host", "propBA", "BA.host"), labels=c("QMD", "propBA", "BA"))

pBA1 <- ggplot(ppdat[ppdat$var=="BA",], aes(x=value, y=yhat, col=focalagent))+geom_smooth()+scale_color_manual(values=p1col)+theme(legend.position="none")+ylab("probability of occurrence")+theme(axis.title.x=element_blank(),axis.text.x=element_blank() )

pBA2 <- ggplot(xm[xm$var=="BA",],aes(x=value, y=focalagent, fill=interaction(focalagent, affected01)))+geom_boxplot()+scale_fill_manual(values=c(adjust_transparency(p1col[1:3], alpha=0.25), p1col[1:3]))+theme(legend.position="none")+ylab("bark beetle")+xlab("basal area")

pQMD1 <- ggplot(ppdat[ppdat$var=="QMD",], aes(x=value, y=yhat, col=focalagent))+geom_smooth()+scale_color_manual(values=p1col)+theme(legend.position="none")+ylab("probability of occurrence")+theme(axis.title.x=element_blank(),axis.text.x=element_blank() )

pQMD2 <- ggplot(xm[xm$var=="QMD",],aes(x=value, y=focalagent, fill=interaction(focalagent, affected01)))+geom_boxplot()+scale_fill_manual(values=c(adjust_transparency(p1col[1:3], alpha=0.25), p1col[1:3]))+theme(legend.position="none")+ylab("")+xlab("QMD")

ppropBA1 <- ggplot(ppdat[ppdat$var=="propBA",], aes(x=value*100, y=yhat, col=focalagent))+geom_smooth()+scale_color_manual(values=p1col)+theme(legend.position="none")+ylab("probability of occurrence")+theme(axis.title.x=element_blank(),axis.text.x=element_blank() )

ppropBA2 <- ggplot(xm[xm$var=="propBA",],aes(x=value*100, y=focalagent, fill=interaction(focalagent, affected01)))+geom_boxplot()+scale_fill_manual(values=c(adjust_transparency(p1col[1:3], alpha=0.25), p1col[1:3]))+theme(legend.position="none")+ylab("")+xlab("% BA")


ppplot <- pBA1  + pQMD1 +theme(axis.title.y=element_blank(),axis.text.y=element_blank()) +ppropBA1 +theme(axis.title.y=element_blank(),axis.text.y=element_blank())+ pBA2 + pQMD2 +theme(axis.text.y=element_blank())  + ppropBA2 +theme(axis.text.y=element_blank()) + plot_layout(ncol=3, heights=c(2,1))

ggsave(here("Results/Figures/PartialDependence.jpg"), plot=ppplot, width=fig.width2,height=fig.width1,units="in")
```



In general, the probability of each bark beetle species occurring increased with host basal area, quadratic mean diameter, and percent basal area. 
```{r partialFig}
knitr::include_graphics(here("Results/Figures/PartialDependence.jpg"))
```

### Stand structure and composition in stands 
```{r FigStandSC,  fig.cap = "A caption", out.width = "322.56pt", eval=T}
datBB.c <-df[!df$focalhost=="Any",] 

QMD.melt <- melt(datBB.c[,c("hosts",paste0("QMD.", c("PIEN", "PICO", "ABLA")))], "hosts")
QMD.melt$variable <- factor(QMD.melt$variable, levels=paste0("QMD.", c("PICO","PIEN",  "ABLA")), labels=c("PICO", "PIEN", "ABLA"), ordered=T)
QMD.melt$facet <- "QMD"

TPH.melt <- melt(datBB.c[,c("hosts",paste0("TPH.", c("PIEN", "PICO", "ABLA")))], "hosts")
TPH.melt$variable <- factor(TPH.melt$variable, levels=paste0("TPH.", c("PICO","PIEN",  "ABLA")), labels=c("PICO", "PIEN", "ABLA"), ordered=T)
TPH.melt$facet <- "TPH"

BA.melt <- melt(datBB.c[,c("hosts",paste0("BA.", c("PIEN", "PICO", "ABLA")))], "hosts")
BA.melt$variable <- factor(BA.melt$variable, levels=paste0("BA.", c("PICO","PIEN",  "ABLA")), labels=c("PICO", "PIEN", "ABLA"), ordered=T)
BA.melt$facet <- "BA"

propBA.melt <-datBB.c[,c("hosts",paste0("BA.", c("PIEN", "PICO", "ABLA", "total")))]
propBA.melt$propBA.PIEN <- propBA.melt$BA.PIEN / propBA.melt$BA.total *100
propBA.melt$propBA.ABLA <- propBA.melt$BA.ABLA / propBA.melt$BA.total *100
propBA.melt$propBA.PICO <- propBA.melt$BA.PICO / propBA.melt$BA.total *100
  
propBA.melt <-  melt(propBA.melt[,c("hosts",paste0("propBA.", c("PIEN", "PICO", "ABLA")))], "hosts")
propBA.melt$variable <- factor(propBA.melt$variable, levels=paste0("propBA.", c("PICO","PIEN",  "ABLA")), labels=c("PICO", "PIEN", "ABLA"), ordered=T)
propBA.melt$facet <- "BA dominance (%)"

plotdat <- rbind(propBA.melt, TPH.melt, BA.melt, QMD.melt)

ggss <- ggplot(plotdat[plotdat$value>0,], aes(x=hosts, y=value,fill=variable))+geom_boxplot(outlier.size = 0.2,color="black",lwd=0.2,position = position_dodge(preserve = "single"))+scale_fill_brewer(palette ="BuPu")+ylab("value")+xlab("")+facet_wrap(.~facet, scales="free_y", ncol=1)+theme(legend.position = "bottom", legend.title=element_blank())

ggsave(here("Results/Figures/Figure-HostStructureByhostIdentity.jpg"), plot=ggss , width=fig.width1.5, height=fig.width1*2, units="in")
knitr::include_graphics(here("Results/Figures/Figure-HostStructureByhostIdentity.jpg"))
```

### Maps
```{r maps all plots and hosts, eval=F}
df.all <- df[df$focalhost == "Any", ]

df.all.sf <- st_as_sf(df.all, coords = c("LON", "LAT"), crs = 4326)

states <-st_read(here("Data/Spatial/States/cb_2018_us_state_20m.shp"),quiet=T)
IMW <- states[states$STUSPS %in% c("AZ", "CO", "ID","MT", "NM", "UT", "WY"),]

ext <- as.matrix(extent(IMW))
#ext[1,1] <- ext[1,1] -0.25
#ext[1,2] <- ext[1,2] +0.25
#ext[2,1] <- ext[2,1] -1
#ext[2,2] <- ext[2,2] +1


map1 <- tm_shape(IMW, bbox=tmaptools::bb(ext)) +  tm_fill(col=grey(level=0.95)) +  tm_borders()  + tm_shape(df.all.sf[df.all.sf$hostsFPlong=="PICO",]) +tm_dots(col="agentsFplong", legend.show = FALSE,size=.0025, palette=rev(p2col)) +tm_compass(position=c(0.9, 0.02), just=c("center", "bottom"), text.size=0.5, size=2)+tm_layout(main.title = "PICO",main.title.size=0.5,main.title.position="center")

map2 <- tm_shape(IMW, bbox=tmaptools::bb(ext)) +  tm_fill(col=grey(level=0.95)) +  tm_borders()  + tm_shape(df.all.sf[df.all.sf$hostsFPlong=="PIEN",]) +tm_dots(col="agentsFplong", legend.show = FALSE,size=.0025, palette=rev(p2col)) +tm_layout(main.title = "PIEN",main.title.size=0.5,main.title.position="center")

map3 <- tm_shape(IMW, bbox=tmaptools::bb(ext)) +  tm_fill(col=grey(level=0.95)) +  tm_borders()  + tm_shape(df.all.sf[df.all.sf$hostsFPlong=="ABLA",]) +tm_dots(col="agentsFplong", legend.show = FALSE,size=.0025, palette=rev(p2col)) +tm_layout(main.title = "ABLA",main.title.size=0.5, main.title.position="center")

map4 <- tm_shape(IMW, bbox=tmaptools::bb(ext)) +  tm_fill(col=grey(level=0.95)) +  tm_borders()  + tm_shape(df.all.sf[df.all.sf$hostsFPlong=="PICO & PIEN",]) +tm_dots(col="agentsFplong", legend.show = FALSE,size=.0025, palette=rev(p2col)) +tm_layout(main.title = "PICO & PIEN",main.title.size=0.5,main.title.position="center")

map5 <- tm_shape(IMW, bbox=tmaptools::bb(ext)) +  tm_fill(col=grey(level=0.95)) +  tm_borders()  + tm_shape(df.all.sf[df.all.sf$hostsFPlong=="PICO & ABLA",]) +tm_dots(col="agentsFplong", legend.show = FALSE,size=.0025, palette=rev(p2col)) +tm_layout(main.title = "PICO & ABLA", main.title.size=0.5, main.title.position="center")

map6 <- tm_shape(IMW, bbox=tmaptools::bb(ext)) +  tm_fill(col=grey(level=0.95)) +  tm_borders()  + tm_shape(df.all.sf[df.all.sf$hostsFPlong=="PIEN & ABLA",]) +tm_dots(col="agentsFplong", legend.show = FALSE,size=.0025, palette=rev(p2col)) +tm_layout(main.title = "PIEN & ABLA", main.title.size=0.5, main.title.position="center")

map7 <- tm_shape(IMW, bbox=tmaptools::bb(ext)) +  tm_fill(col=grey(level=0.95)) +  tm_borders()  + tm_shape(df.all.sf[df.all.sf$hostsFPlong=="PICO, PIEN, & ABLA",]) +tm_dots(col="agentsFplong", legend.show = FALSE,size=.0025, palette=rev(p2col))+tm_layout(main.title = "PICO, PIEN, & ABLA", main.title.size=0.5, main.title.position="center")

legend.map <- tm_shape(IMW, bbox=tmaptools::bb(ext)) +  tm_fill(col=grey(level=0.95)) +  tm_borders()  + tm_shape(df.all.sf[df.all.sf$hostsFPlong=="PICO, PIEN, & ABLA",]) +tm_dots(col="agentsFplong", size=4, title="bark beetle species",  palette=rev(p2col))+tm_layout(legend.only = TRUE,legend.text.size = 0.5,legend.title.size = 0.65)+tm_scale_bar(position = c(0.5,0.16), text.size=0.5, just="center", breaks=c(0,250,500))

Fig.file <- here("Results/Figures/Figure-Map-Allplots.jpg")
jpeg(Fig.file, width=fig.width1.5, height=fig.width2/2, units="in", res=300)
tmap_arrange(map1, map2,map3, map4, map5, map6, map7,legend.map, nrow=2)
whatever <- dev.off()

```

```{r generate maps, eval=F}
bbo.dat<- merge(BBpred, df, id.vars="PLT_CN", all=T)

df.all <- bbo.dat[bbo.dat$focalhost == "Any", ]

df.all.sf <- st_as_sf(df.all, coords = c("LON", "LAT"), crs = 4326)


states <-st_read(here("Data/Spatial/States/cb_2018_us_state_20m.shp"),quiet=T)
IMW <- states[states$STUSPS %in% c("AZ", "CO", "ID","MT", "NM", "UT", "WY"),]

ext <- as.matrix(extent(IMW))
#ext[1,1] <- ext[1,1] -0.25
#ext[1,2] <- ext[1,2] +0.25
#ext[2,1] <- ext[2,1] -1
#ext[2,2] <- ext[2,2] +1


map1 <- tm_shape(IMW, bbox=tmaptools::bb(ext)) +  tm_fill(col=grey(level=0.95)) +  tm_borders()  + tm_shape(df.all.sf[df.all.sf$hostsFPlong=="PICO",]) +tm_dots(col="agentsFplong", legend.show = FALSE,size=.0025, palette=rev(p2col)) +tm_compass(position=c(0.9, 0.02), just=c("center", "bottom"), text.size=0.5, size=2)+tm_layout(main.title = "PICO",main.title.size=0.5,main.title.position="center")

map2 <- tm_shape(IMW, bbox=tmaptools::bb(ext)) +  tm_fill(col=grey(level=0.95)) +  tm_borders()  + tm_shape(df.all.sf[df.all.sf$hostsFPlong=="PIEN",]) +tm_dots(col="agentsFplong", legend.show = FALSE,size=.0025, palette=rev(p2col)) +tm_layout(main.title = "PIEN",main.title.size=0.5,main.title.position="center")

map3 <- tm_shape(IMW, bbox=tmaptools::bb(ext)) +  tm_fill(col=grey(level=0.95)) +  tm_borders()  + tm_shape(df.all.sf[df.all.sf$hostsFPlong=="ABLA",]) +tm_dots(col="agentsFplong", legend.show = FALSE,size=.0025, palette=rev(p2col)) +tm_layout(main.title = "ABLA",main.title.size=0.5, main.title.position="center")

map4 <- tm_shape(IMW, bbox=tmaptools::bb(ext)) +  tm_fill(col=grey(level=0.95)) +  tm_borders()  + tm_shape(df.all.sf[df.all.sf$hostsFPlong=="PICO & PIEN",]) +tm_dots(col="agentsFplong", legend.show = FALSE,size=.0025, palette=rev(p2col)) +tm_layout(main.title = "PICO & PIEN",main.title.size=0.5,main.title.position="center")

map5 <- tm_shape(IMW, bbox=tmaptools::bb(ext)) +  tm_fill(col=grey(level=0.95)) +  tm_borders()  + tm_shape(df.all.sf[df.all.sf$hostsFPlong=="PICO & ABLA",]) +tm_dots(col="agentsFplong", legend.show = FALSE,size=.0025, palette=rev(p2col)) +tm_layout(main.title = "PICO & ABLA", main.title.size=0.5, main.title.position="center")

map6 <- tm_shape(IMW, bbox=tmaptools::bb(ext)) +  tm_fill(col=grey(level=0.95)) +  tm_borders()  + tm_shape(df.all.sf[df.all.sf$hostsFPlong=="PIEN & ABLA",]) +tm_dots(col="agentsFplong", legend.show = FALSE,size=.0025, palette=rev(p2col)) +tm_layout(main.title = "PIEN & ABLA", main.title.size=0.5, main.title.position="center")

map7 <- tm_shape(IMW, bbox=tmaptools::bb(ext)) +  tm_fill(col=grey(level=0.95)) +  tm_borders()  + tm_shape(df.all.sf[df.all.sf$hostsFPlong=="PICO, PIEN, & ABLA",]) +tm_dots(col="agentsFplong", legend.show = FALSE,size=.0025, palette=rev(p2col))+tm_layout(main.title = "PICO, PIEN, & ABLA", main.title.size=0.5, main.title.position="center")

legend.map <- tm_shape(IMW, bbox=tmaptools::bb(ext)) +  tm_fill(col=grey(level=0.95)) +  tm_borders()  + tm_shape(df.all.sf[df.all.sf$hostsFPlong=="PICO, PIEN, & ABLA",]) +tm_dots(col="agentsFplong", size=4, title="bark beetle species",  palette=rev(p2col))+tm_layout(legend.only = TRUE,legend.text.size = 0.5,legend.title.size = 0.65)+tm_scale_bar(position = c(0.5,0.16), text.size=0.5, just="center", breaks=c(0,250,500))

Fig.file <- here("Results/Figures/Figure-Map.jpg")
jpeg(Fig.file, width=fig.width1.5, height=fig.width2/2, units="in", res=300)
tmap_arrange(map1, map2,map3, map4, map5, map6, map7,legend.map, nrow=2)
whatever <- dev.off()

```

```{r FigMap, fig.cap="a caption", out.width = "504.8pt"}
knitr::include_graphics(here("Results/Figures/Figure-Map.jpg"))
```

```{r map study area of hosts, eval=F}
f19 <- stars::read_stars(here("Data/Spatial/ITSPM2002-subalpine/f19/w001001.adf"), proxy=F)
f93 <- stars::read_stars(here("Data/Spatial/ITSPM2002-subalpine/f93/w001001.adf"), proxy=F)
f108 <- stars::read_stars(here("Data/Spatial/ITSPM2002-subalpine/f108/w001001.adf"), proxy=F)

# reclassify to rasters to presence (1) and absence (0)
f19[f19>0] <- 1 
f93[f93>0] <- 1
f108[f108>0] <- 1

# define areas of multiple hosts
f108f93 <- f108 + f93 # add 
f108f93[f108f93<2]<- 0 # reclassify
f108f93[f108f93==2]<- 1 # reclassify
f108f19 <- f108 + f19
f108f19[f108f19<2]<- 0 # reclassify
f108f19[f108f19==2]<- 1 # reclassify
f93f19 <- f93 + f19
f93f19[f93f19<2]<- 0  # reclassify
f93f19[f93f19==2]<- 1 # reclassify

f108f93f19 <- f108 + f93 + f19

# define areas of one host
f108f93f19re1 <-f108f93f19
f108f93f19re1 [f108f93f19re1 ==1 ]<-1
f108f93f19re1 [f108f93f19re1>1]<-0 

# define areas of two hosts
f108f93f19re2 <-f108f93f19
f108f93f19re2 [f108f93f19re2 ==1 ]<-0
f108f93f19re2 [f108f93f19re2==3]<-0 
f108f93f19re2 [f108f93f19re2 ==2 ]<-1

# limit maps of presence (1) and absence (0) to only areas with one host
f108 <- f108 * f108f93f19re1 
f93 <- f93 * f108f93f19re1
f19 <- f19 * f108f93f19re1 
f93[f93==1]<- 2 # give unique labels
f19[f19==1]<- 3 # give unique labels

# create maps of two hosts limited to areas with two hosts
f108f93  <- f108f93 * f108f93f19re2 
f108f93[f108f93==1]<-4 # give unique labels

f108f19 <- f108f19 * f108f93f19re2
f108f19[f108f19==1]<-5 # give unique label

f93f19 <- f93f19 * f108f93f19re2
f93f19[f93f19==1]<-6 # give unique labels

# create maps of all three hosts
f108f93f19[f108f93f19<=2]<-0
f108f93f19[f108f93f19==3]<-7 # give unique labels

fplot <- f108 + f93 + f19 + f108f93 + f108f19 + f93f19+ f108f93f19
st_crs(fplot) <- "EPSG:5070" # assign projection


fplot[fplot==0] <-NA

states <-st_read(here("Data/Spatial/States/cb_2018_us_state_20m.shp"),quiet=T)
IMW <- states[states$STUSPS %in% c("AZ", "CO", "ID","MT", "NM", "UT", "WY"),]
notIMW <- states[!states$STUSPS %in% c("AZ", "CO", "ID","MT", "NM", "UT", "WY"),]
IMW <- st_transform(IMW, "EPSG:5070")
notIMW <- st_transform(notIMW, "EPSG:5070")

ext <- as.matrix(extent(IMW))

sa.tmap <- tm_shape(IMW, bbox=tmaptools::bb(ext)) + tm_fill(col="#f5f5f5")+tm_borders()+tm_shape(fplot) +tm_raster(style = "cat", palette = c("#8c510a", "#bf812d", "#dfc27d", "#80cdc1", "#35978f", "#01665e", "#003c30"), colorNA=NULL, legend.show = TRUE, title="Hosts                    ", labels = c("PICO", "PIEN", "ABLA", "PICO & PIEN", "PICO & ABLA", "PIEN & ABLA", "PICO, PIEN, & ABLA"))+ tm_shape(notIMW) + tm_fill(col="white")+tm_compass(position=c(0.95, 0.88), just=c("center", "bottom"))+tm_layout(legend.bg.color="white")+tm_graticules(lines=FALSE)+tm_layout(legend.outside=TRUE,legend.text.size=0.55)+tm_scale_bar(position = c(0.01, 0.001), just="left", breaks=c(0,100),text.size=1.1)+tm_shape(IMW) +tm_borders()

Fig.file <- here("Results/Figures/Figure-Studyarea.jpg")
jpeg(Fig.file, width=fig.width1.5,height=fig.width1.5,units="in", res=300)
sa.tmap 
whatever <- dev.off()
```

```{r FigSA, fig.cap = "The distribution of host species presence across the study area. Data are from the Individual Tree Species Atlas (Ellenwood et al. 2015) and represent conditions in ca. 2002.", out.width = "322.56pt"}
knitr::include_graphics( here("Results/Figures/Figure-Studyarea.jpg"))
```

## Quatile comparison
```{r select plots with large & abundant hosts, eval=F}
df.sub <- df

PICO.BA.threshold <- quantile(df.sub[df.sub$agentMPB=="MPB", ]$BA.PICO, 0.1)
PIEN.BA.threshold <- quantile(df.sub[df.sub$agentSB=="SB", ]$BA.PIEN, 0.1)
ABLA.BA.threshold <- quantile(df.sub[df.sub$agentWBBB=="WBBB", ]$BA.ABLA, 0.1)

PICO.QMD.threshold <- quantile(df.sub[df.sub$agentMPB=="MPB", ]$QMD.PICO, 0.1)
PIEN.QMD.threshold <- quantile(df.sub[df.sub$agentSB=="SB", ]$QMD.PIEN, 0.1)
ABLA.QMD.threshold <- quantile(df.sub[df.sub$agentWBBB=="WBBB", ]$QMD.ABLA, 0.1)

# PICO, PIEN & ABLA
df.sub.PICO.PIEN.ABLA <- df.sub[df.sub$BA.PICO >= PICO.BA.threshold & df.sub$BA.PIEN >= PIEN.BA.threshold & df.sub$BA.ABLA >= ABLA.BA.threshold, ]

df.sub.PICO.PIEN.ABLA <- df.sub.PICO.PIEN.ABLA[df.sub.PICO.PIEN.ABLA$QMD.PICO >= PICO.QMD.threshold & df.sub.PICO.PIEN.ABLA$QMD.PIEN >= PIEN.QMD.threshold & df.sub.PICO.PIEN.ABLA$QMD.ABLA >= ABLA.QMD.threshold, ]

df.sub.PICO.PIEN.ABLA$suitablehosts2 <- "PICO, PIEN & ABLA"
df.sub.PICO.PIEN.ABLA$nhosts2 <- 3

# PICO & PIEN
df.sub.PICO.PIEN<- df.sub[df.sub$BA.PICO >= PICO.BA.threshold & df.sub$BA.PIEN >= PIEN.BA.threshold, ]

df.sub.PICO.PIEN <- df.sub.PICO.PIEN[df.sub.PICO.PIEN$QMD.PICO >= PICO.QMD.threshold & df.sub.PICO.PIEN$QMD.PIEN >= PIEN.QMD.threshold, ]

df.sub.PICO.PIEN$suitablehosts2 <- "PICO & PIEN"
df.sub.PICO.PIEN <- df.sub.PICO.PIEN[!(df.sub.PICO.PIEN$PLT_CN %in% df.sub.PICO.PIEN$PLT_CN), ]
df.sub.PICO.PIEN$nhosts2 <- 2

# PICO & ABLA
df.sub.PICO.ABLA<- df.sub[df.sub$BA.PICO >= PICO.BA.threshold & df.sub$BA.ABLA >= ABLA.BA.threshold, ]

df.sub.PICO.ABLA <- df.sub.PICO.ABLA[df.sub.PICO.ABLA$QMD.PICO >= PICO.QMD.threshold & df.sub.PICO.ABLA$QMD.ABLA >= ABLA.QMD.threshold, ]

df.sub.PICO.ABLA$suitablehosts2 <- "PICO & ABLA"
df.sub.PICO.ABLA$nhosts2 <- 2

df.sub.PICO.ABLA<- df.sub.PICO.ABLA[!(df.sub.PICO.ABLA$PLT_CN %in% df.sub.PICO.PIEN.ABLA$PLT_CN), ]


# PIEN & ABLA
df.sub.PIEN.ABLA<- df.sub[df.sub$BA.PIEN >= PIEN.BA.threshold & df.sub$BA.ABLA >= ABLA.BA.threshold, ]

df.sub.PIEN.ABLA <- df.sub.PIEN.ABLA[df.sub.PIEN.ABLA$QMD.PIEN >= PIEN.QMD.threshold & df.sub.PIEN.ABLA$QMD.ABLA >= ABLA.QMD.threshold, ]

df.sub.PIEN.ABLA$suitablehosts2 <- "PIEN & ABLA"
df.sub.PIEN.ABLA$nhosts2 <- 2

df.sub.PIEN.ABLA <- df.sub.PIEN.ABLA[!(df.sub.PIEN.ABLA$PLT_CN %in% df.sub.PICO.PIEN.ABLA$PLT_CN), ]

###
df.focal2 <- rbind(df.sub.PICO.ABLA, df.sub.PICO.PIEN)
df.focal2 <- rbind(df.focal2, df.sub.PICO.PIEN)
df.focal2 <- rbind(df.focal2, df.sub.PICO.PIEN.ABLA)

## Affected hosts
affectedhosts2 <- df.focal2 %>% group_by(suitablehosts2, afp2colfected) %>% summarise(n = n())%>% mutate(freq = prop.table(n))
affectedhosts2[affectedhosts2$affected=="affected",]
affectednhosts2 <- df.focal2 %>% group_by(nhosts2, affected) %>% summarise(n = n())%>% mutate(freq = prop.table(n))
affectednhosts2[affectednhosts2$affected=="affected",]


```


